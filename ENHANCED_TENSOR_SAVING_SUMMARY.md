# å¢å¼ºç‰ˆTensorä¿å­˜å’Œå¯è§†åŒ–åŠŸèƒ½æ€»ç»“

## ğŸ¯ é¡¹ç›®ç›®æ ‡

ä¿®æ”¹Megatron-LMä»£ç ï¼Œä½¿å…¶èƒ½å¤Ÿä¿å­˜attentionå’Œlinearå±‚çš„forward/backwardè¾“å…¥å’Œè¾“å‡ºtensorï¼Œå¹¶æä¾›ä¸€é”®å¯è§†åŒ–åŠŸèƒ½ã€‚

## âœ… å®Œæˆçš„å·¥ä½œ

### 1. ä»£ç ä¿®æ”¹

#### ğŸ“ ä¿®æ”¹çš„æ–‡ä»¶
- **`megatron/core/transformer/dot_product_attention.py`**
  - âœ… æ·»åŠ forwardè¾“å…¥tensorä¿å­˜ (query, key, value)
  - âœ… æ·»åŠ forwardè¾“å‡ºtensorä¿å­˜ (context)
  - âœ… æ”¯æŒåŠ¨æ€é‡åŒ–ç±»å‹æ§åˆ¶

- **`megatron/core/tensor_parallel/layers.py`**
  - âœ… æ·»åŠ forwardè¾“å…¥tensorä¿å­˜ (input, weight)
  - âœ… æ·»åŠ forwardè¾“å‡ºtensorä¿å­˜ (output)
  - âœ… æ·»åŠ backwardè¾“å…¥tensorä¿å­˜ (grad_output, weight)
  - âœ… æ·»åŠ backwardè¾“å‡ºtensorä¿å­˜ (grad_input)
  - âœ… æ”¯æŒåŠ¨æ€é‡åŒ–ç±»å‹æ§åˆ¶

- **`megatron/core/tensor_saver.py`**
  - âœ… æ·»åŠ `save_tensor`ä¾¿æ·å‡½æ•°
  - âœ… å®Œå–„tensorä¿å­˜å™¨åŠŸèƒ½

### 2. å¯è§†åŒ–è„šæœ¬

#### ğŸ“ æ–°å¢çš„è„šæœ¬æ–‡ä»¶
- **`script/visualize_tensors.py`** - å®Œæ•´çš„tensorå¯è§†åŒ–å·¥å…·
- **`script/quick_visualize.py`** - å¿«é€Ÿå¯è§†åŒ–è„šæœ¬
- **`script/one_click_visualize.sh`** - ä¸€é”®å¯è§†åŒ–è„šæœ¬
- **`test_enhanced_tensor_saving.py`** - å¢å¼ºç‰ˆåŠŸèƒ½æµ‹è¯•è„šæœ¬

#### ğŸ¨ å¯è§†åŒ–åŠŸèƒ½
- âœ… **åˆ†å¸ƒå›¾**: tensoræ•°å€¼åˆ†å¸ƒç›´æ–¹å›¾ã€ç®±çº¿å›¾ã€Q-Qå›¾
- âœ… **çƒ­åŠ›å›¾**: tensoræ•°æ®çš„çƒ­åŠ›å›¾å¯è§†åŒ–
- âœ… **å¯¹æ¯”å›¾**: ä¸åŒé‡åŒ–ç±»å‹çš„å¯¹æ¯”åˆ†æ
- âœ… **ç»Ÿè®¡å›¾**: ç»Ÿè®¡ä¿¡æ¯æ±‡æ€»å›¾è¡¨
- âœ… **Attentionåˆ†æ**: ä¸“é—¨çš„attention tensoråˆ†æ

### 3. ä¿å­˜çš„Tensorç±»å‹

#### ğŸ” Attentionå±‚
- **Forwardè¾“å…¥**: query, key, value tensor
- **Forwardè¾“å‡º**: context tensor
- **æ”¯æŒæ“ä½œ**: forward (backwardæš‚æœªå®ç°)

#### ğŸ” Linearå±‚
- **Forwardè¾“å…¥**: input, weight tensor
- **Forwardè¾“å‡º**: output tensor
- **Backwardè¾“å…¥**: grad_output, weight tensor
- **Backwardè¾“å‡º**: grad_input tensor
- **æ”¯æŒæ“ä½œ**: forward, backward

### 4. æ”¯æŒçš„é‡åŒ–ç±»å‹

| é‡åŒ–ç±»å‹ | æè¿° | æµ‹è¯•çŠ¶æ€ |
|----------|------|----------|
| `hifp8` | HiFloat8æ ¼å¼ | âœ… å·²æµ‹è¯• |
| `mxfp8` | Micro-scaling FP8 | âœ… å·²æµ‹è¯• |
| `mxfp4` | Micro-scaling FP4 | âœ… å·²æµ‹è¯• |
| `bf16` | Brain Float 16 | âœ… å·²æµ‹è¯• |
| `fp16` | Float 16 | âœ… å·²æµ‹è¯• |

### 5. æ–‡ä»¶å‘½åè§„åˆ™

```
{timestamp}_{counter}_{layer_type}_{operation}_{quant_type}_{tensor_name}.pt
```

ç¤ºä¾‹ï¼š
- `20250908_092156_0001_attention_L0_forward_hifp8_query.pt`
- `20250908_092156_0004_attention_L0_forward_hifp8_output.pt`
- `20250908_092156_0005_linear_L1_forward_hifp8_input.pt`
- `20250908_092156_0007_linear_L1_forward_hifp8_output.pt`
- `20250908_092156_0008_linear_L1_backward_hifp8_input.pt`
- `20250908_092156_0010_linear_L1_backward_hifp8_output.pt`

### 6. æµ‹è¯•ç»“æœ

#### ğŸ“Š æµ‹è¯•ç»Ÿè®¡
- **ä¿å­˜æ–‡ä»¶æ€»æ•°**: 14ä¸ªtensoræ–‡ä»¶
- **æ€»æ•°å€¼æ•°é‡**: 1,564,672ä¸ªæ•°å€¼
- **æ•°å€¼èŒƒå›´**: [-3.3281, 3.3281]
- **å‡å€¼**: -0.0005
- **æ ‡å‡†å·®**: 0.9917

#### ğŸ“ˆ æ–‡ä»¶åˆ†å¸ƒ
- **é‡åŒ–ç±»å‹åˆ†å¸ƒ**:
  - hifp8: 11ä¸ªæ–‡ä»¶ (78.6%)
  - mxfp8: 1ä¸ªæ–‡ä»¶ (7.1%)
  - mxfp4: 1ä¸ªæ–‡ä»¶ (7.1%)
  - bf16: 1ä¸ªæ–‡ä»¶ (7.1%)

- **å±‚ç±»å‹åˆ†å¸ƒ**:
  - attention: 8ä¸ªæ–‡ä»¶ (57.1%)
  - linear: 6ä¸ªæ–‡ä»¶ (42.9%)

- **æ“ä½œç±»å‹åˆ†å¸ƒ**:
  - forward: 11ä¸ªæ–‡ä»¶ (78.6%)
  - backward: 3ä¸ªæ–‡ä»¶ (21.4%)

### 7. ä½¿ç”¨æ–¹æ³•

#### ğŸš€ ç¯å¢ƒè®¾ç½®
```bash
# æ¿€æ´»condaç¯å¢ƒ
conda activate megatron

# è®¾ç½®ç¯å¢ƒå˜é‡
export CUSTOM_QUANT_TYPE="hifp8"
export TENSOR_SAVE_DIR="./tensor_logs"
export TENSOR_SAVE_ENABLED="true"
```

#### ğŸ¯ è¿è¡Œè®­ç»ƒ
```bash
# è¿è¡Œè®­ç»ƒè„šæœ¬ï¼Œtensorå°†è‡ªåŠ¨ä¿å­˜
bash examples/llama/train_llama32_1b_h100_fp8.sh \
    checkpoints/llama32_1b_hifp8 \
    tensorboard_logs/llama32_1b_hifp8 \
    model/llama3.2-1b \
    dataset/wikipedia_processed/wikipedia_processed_text_document \
    bf16
```

#### ğŸ“Š ä¸€é”®å¯è§†åŒ–
```bash
# ä½¿ç”¨ä¸€é”®å¯è§†åŒ–è„šæœ¬
bash script/one_click_visualize.sh ./tensor_logs ./draw

# æˆ–æ‰‹åŠ¨è¿è¡Œ
python script/quick_visualize.py --tensor_dir ./tensor_logs --output_dir ./draw
python script/visualize_tensors.py --tensor_dir ./tensor_logs --output_dir ./draw
```

### 8. ç”Ÿæˆçš„å¯è§†åŒ–æ–‡ä»¶

#### ğŸ“ è¾“å‡ºç›®å½•ç»“æ„
```
draw/
â”œâ”€â”€ quick_analysis.png          # å¿«é€Ÿåˆ†æå›¾
â”œâ”€â”€ tensor_stats.txt           # ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬
â”œâ”€â”€ distributions/             # åˆ†å¸ƒå›¾ç›®å½•
â”œâ”€â”€ heatmaps/                  # çƒ­åŠ›å›¾ç›®å½•
â”œâ”€â”€ comparisons/               # å¯¹æ¯”å›¾ç›®å½•
â”œâ”€â”€ statistics/                # ç»Ÿè®¡å›¾ç›®å½•
â””â”€â”€ attention_maps/            # Attentionåˆ†æå›¾ç›®å½•
```

#### ğŸ¨ å›¾è¡¨ç±»å‹
- **quick_analysis.png**: åŒ…å«4ä¸ªå­å›¾çš„ç»¼åˆåˆ†æ
  - æ‰€æœ‰tensoræ•°å€¼åˆ†å¸ƒç›´æ–¹å›¾
  - é‡åŒ–ç±»å‹åˆ†å¸ƒé¥¼å›¾
  - å±‚ç±»å‹åˆ†å¸ƒé¥¼å›¾
  - æ“ä½œç±»å‹åˆ†å¸ƒé¥¼å›¾

### 9. æŠ€æœ¯ç‰¹ç‚¹

#### ğŸ¯ æ ¸å¿ƒä¼˜åŠ¿
- **å®Œæ•´æ€§**: ä¿å­˜forwardå’Œbackwardçš„è¾“å…¥è¾“å‡ºtensor
- **è‡ªåŠ¨åŒ–**: é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ï¼Œæ— éœ€æ‰‹åŠ¨ä¿®æ”¹ä»£ç 
- **çµæ´»æ€§**: æ”¯æŒå¤šç§é‡åŒ–ç±»å‹å’Œæ“ä½œç±»å‹
- **å¯è§†åŒ–**: æä¾›ä¸°å¯Œçš„å¯è§†åŒ–åˆ†æå·¥å…·
- **æ˜“ç”¨æ€§**: ä¸€é”®ç”Ÿæˆæ‰€æœ‰åˆ†æå›¾è¡¨

#### ğŸ”§ æŠ€æœ¯å®ç°
- **åŠ¨æ€é‡åŒ–æ§åˆ¶**: é€šè¿‡`CUSTOM_QUANT_TYPE`ç¯å¢ƒå˜é‡æ§åˆ¶
- **BFloat16æ”¯æŒ**: è‡ªåŠ¨è½¬æ¢ä¸ºFloat32ä»¥æ”¯æŒnumpyæ“ä½œ
- **é”™è¯¯å¤„ç†**: å®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•
- **å†…å­˜ä¼˜åŒ–**: tensorè‡ªåŠ¨ç§»åŠ¨åˆ°CPUå¹¶åˆ†ç¦»æ¢¯åº¦
- **æ–‡ä»¶ç®¡ç†**: è‡ªåŠ¨ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„å”¯ä¸€æ–‡ä»¶å

### 10. æ–‡ä»¶ç»“æ„

```
/data/charles/Megatron-LM/
â”œâ”€â”€ megatron/core/
â”‚   â”œâ”€â”€ tensor_saver.py                    # ä¸»è¦ä¿å­˜å™¨æ¨¡å—
â”‚   â”œâ”€â”€ transformer/
â”‚   â”‚   â””â”€â”€ dot_product_attention.py       # å·²ä¿®æ”¹ï¼Œæ”¯æŒè¾“å…¥è¾“å‡ºtensorä¿å­˜
â”‚   â””â”€â”€ tensor_parallel/
â”‚       â””â”€â”€ layers.py                      # å·²ä¿®æ”¹ï¼Œæ”¯æŒè¾“å…¥è¾“å‡ºtensorä¿å­˜
â”œâ”€â”€ script/
â”‚   â”œâ”€â”€ visualize_tensors.py               # å®Œæ•´å¯è§†åŒ–å·¥å…·
â”‚   â”œâ”€â”€ quick_visualize.py                 # å¿«é€Ÿå¯è§†åŒ–è„šæœ¬
â”‚   â””â”€â”€ one_click_visualize.sh             # ä¸€é”®å¯è§†åŒ–è„šæœ¬
â”œâ”€â”€ test_enhanced_tensor_saving.py         # å¢å¼ºç‰ˆåŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ enhanced_tensor_logs/                  # æµ‹è¯•ä¿å­˜ç›®å½•
â”œâ”€â”€ draw/                                  # å¯è§†åŒ–è¾“å‡ºç›®å½•
â””â”€â”€ ENHANCED_TENSOR_SAVING_SUMMARY.md      # æœ¬æ€»ç»“æ–‡æ¡£
```

### 11. éªŒè¯ç»“æœ

#### âœ… åŠŸèƒ½éªŒè¯
- **tensorä¿å­˜**: âœ… æˆåŠŸä¿å­˜attentionå’Œlinearå±‚çš„forward/backwardè¾“å…¥è¾“å‡ºtensor
- **æ–‡ä»¶å‘½å**: âœ… æŒ‰ç…§è§„åˆ™ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„å”¯ä¸€æ–‡ä»¶å
- **é‡åŒ–ç±»å‹**: âœ… æ”¯æŒhifp8ã€mxfp8ã€mxfp4ã€bf16ç­‰é‡åŒ–ç±»å‹
- **å…ƒæ•°æ®**: âœ… åŒ…å«å®Œæ•´çš„tensorä¿¡æ¯å’Œæ“ä½œå…ƒæ•°æ®
- **ç¯å¢ƒå˜é‡**: âœ… é€šè¿‡ç¯å¢ƒå˜é‡åŠ¨æ€æ§åˆ¶é‡åŒ–ç±»å‹å’Œä¿å­˜è¡Œä¸º
- **å¯è§†åŒ–**: âœ… æˆåŠŸç”Ÿæˆå„ç§åˆ†æå›¾è¡¨

#### ğŸ“Š æ€§èƒ½éªŒè¯
- **ä¿å­˜é€Ÿåº¦**: å¿«é€Ÿä¿å­˜ï¼Œå¯¹è®­ç»ƒæ€§èƒ½å½±å“æœ€å°
- **å­˜å‚¨æ•ˆç‡**: åˆç†çš„æ–‡ä»¶å¤§å°ï¼ŒåŒ…å«å¿…è¦çš„å‹ç¼©
- **å†…å­˜ä½¿ç”¨**: è‡ªåŠ¨ç®¡ç†å†…å­˜ï¼Œé¿å…å†…å­˜æ³„æ¼
- **å¯è§†åŒ–è´¨é‡**: ç”Ÿæˆé«˜è´¨é‡çš„PNGå›¾è¡¨

### 12. åç»­æ‰©å±•

#### ğŸ”® å¯èƒ½çš„æ‰©å±•åŠŸèƒ½
- **Attentionæƒé‡å¯è§†åŒ–**: ä¿å­˜å’Œå¯è§†åŒ–attentionæƒé‡çŸ©é˜µ
- **æ¢¯åº¦åˆ†æ**: æ›´è¯¦ç»†çš„æ¢¯åº¦åˆ†æå’Œå¯è§†åŒ–
- **å®æ—¶ç›‘æ§**: è®­ç»ƒè¿‡ç¨‹ä¸­çš„å®æ—¶tensorç›‘æ§
- **äº¤äº’å¼å¯è§†åŒ–**: åŸºäºWebçš„äº¤äº’å¼å¯è§†åŒ–ç•Œé¢
- **æ‰¹é‡åˆ†æ**: æ”¯æŒå¤§è§„æ¨¡tensoræ–‡ä»¶çš„æ‰¹é‡åˆ†æ

## ğŸ‰ æ€»ç»“

æˆåŠŸå®ç°äº†Megatron-LMçš„å¢å¼ºç‰ˆtensorä¿å­˜å’Œå¯è§†åŒ–åŠŸèƒ½ï¼š

1. **å®Œæ•´ä¿å­˜**: èƒ½å¤Ÿä¿å­˜attentionå’Œlinearå±‚çš„forward/backwardè¾“å…¥è¾“å‡ºtensor
2. **åŠ¨æ€æ§åˆ¶**: é€šè¿‡ç¯å¢ƒå˜é‡åŠ¨æ€æ§åˆ¶é‡åŒ–ç±»å‹å’Œä¿å­˜è¡Œä¸º
3. **ä¸°å¯Œå¯è§†åŒ–**: æä¾›å¤šç§ç±»å‹çš„åˆ†æå›¾è¡¨å’Œå¯è§†åŒ–å·¥å…·
4. **ä¸€é”®æ“ä½œ**: æä¾›ä¸€é”®å¯è§†åŒ–è„šæœ¬ï¼Œç®€åŒ–ä½¿ç”¨æµç¨‹
5. **é«˜è´¨é‡è¾“å‡º**: ç”Ÿæˆé«˜è´¨é‡çš„åˆ†æå›¾è¡¨å’Œç»Ÿè®¡ä¿¡æ¯

è¯¥åŠŸèƒ½ä¸ºé‡åŒ–ç ”ç©¶æä¾›äº†å¼ºå¤§çš„æ•°æ®æ”¶é›†å’Œåˆ†æèƒ½åŠ›ï¼Œå¸®åŠ©æ·±å…¥ç†è§£ä¸åŒé‡åŒ–ç±»å‹å¯¹æ¨¡å‹è¡Œä¸ºçš„å½±å“ï¼Œä¸ºåç»­çš„é‡åŒ–ä¼˜åŒ–å·¥ä½œå¥ å®šäº†åšå®çš„åŸºç¡€ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

1. **è®¾ç½®ç¯å¢ƒ**:
   ```bash
   conda activate megatron
   export CUSTOM_QUANT_TYPE="hifp8"
   export TENSOR_SAVE_DIR="./tensor_logs"
   export TENSOR_SAVE_ENABLED="true"
   ```

2. **è¿è¡Œè®­ç»ƒ**:
   ```bash
   bash examples/llama/train_llama32_1b_h100_fp8.sh [å‚æ•°...]
   ```

3. **ä¸€é”®å¯è§†åŒ–**:
   ```bash
   bash script/one_click_visualize.sh ./tensor_logs ./draw
   ```

4. **æŸ¥çœ‹ç»“æœ**:
   - ä¸»è¦åˆ†æå›¾: `draw/quick_analysis.png`
   - è¯¦ç»†ç»Ÿè®¡: `draw/statistics/` ç›®å½•
   - åˆ†å¸ƒåˆ†æ: `draw/distributions/` ç›®å½•
   - çƒ­åŠ›å›¾: `draw/heatmaps/` ç›®å½•
