# Data Processing for LLM Pretraining

Documentation for all the scripts can be located in the `examples/data-processing/docs` folder. These documentations have been generated by ChatGPT and have undergone review.

For LLM data processing, follow these steps once the data is in the Azure container:

## Merge the Shards
   - To train the data, merge the shards based on domains. You can find all the merge scripts in the `examples/data-processing/merge_shards_runner/` folder. It's important to note that this step is not dependent on the model, which is why these scripts are located outside of the experiments folder.
   - Documentation of the merge shards are [here](./docs/merge_shards.md)

   **TODO (Additional PR Required):**
   - The merge script cannot split a shard into smaller pieces if the shard size is too large.
   - If the file sizes are too small but the requested shard size is too large, the script won't function as expected. Refer to the script's `Note` section for a better understanding.

## Tokenize the Shards
   - Tokenize the data and store it in a specific memory-mapped format. This is done in both NeMo and Megatron-LM. This section is an integral part of the experiment and should be placed within the root directory of the experiment folder (i.e., `examples/data-processing/pretrain-llama`).
   - Documentation of the tokenizations are [here](./docs/tokenize_shards.md)

   **TODO (Additional PR Required):**
   - NeMo's tokenization consumes excessive memory, rendering it unsuitable for 128GB CPU nodes. Investigate and resolve memory leaks.

## Calculate the Iterator Probability 
    
This step involves experiment-specific arguments and should be placed inside each of the experiment folders (e.g., `examples/data-processing/pretrain-llama/training/llama_en_reasoning`). This represents the lowest level of the experiment folder hierarchy. For each of the experiments, we use the `examples/data-processing/data_ratio_from_file.py` script to obtain the iterator selection probability. Please refer to the script documentation for a detailed understanding.

    
    usage: data_ratio_from_file.py [-h] [--source-prefix-paths SOURCE_PREFIX_PATHS] [--prefix-paths-from-json PREFIX_PATHS_FROM_JSON]
                               --domain-ratio-from-json DOMAIN_RATIO_FROM_JSON --lang-select-prob-json LANG_SELECT_PROB_JSON
                               --exclude-iterator-json EXCLUDE_ITERATOR_JSON --total-token TOTAL_TOKEN [--verbose]
                               [--export-for-script EXPORT_FOR_SCRIPT] [--prefix-for-file-path PREFIX_FOR_FILE_PATH]

    options:
    -h, --help            display this help message and exit
    --source-prefix-paths SOURCE_PREFIX_PATHS
                            Glob path to the folder where all the bin and idx files are located.
    --prefix-paths-from-json PREFIX_PATHS_FROM_JSON
                            File names listed in a JSON file.
    --domain-ratio-from-json DOMAIN_RATIO_FROM_JSON
                            Domain multiplier from a JSON file.
    --lang-select-prob-json LANG_SELECT_PROB_JSON
                            Path to a JSON file that indicates the language selection probability.
    --exclude-iterator-json EXCLUDE_ITERATOR_JSON
                            Path to a JSON file that lists the restricted iterator names.
    --total-token TOTAL_TOKEN
                            Total tokens to be sampled.
    --verbose             Print additional information.
    --export-for-script EXPORT_FOR_SCRIPT
                            Export output to this file for running it in Megatron format arguments.
    --prefix-for-file-path PREFIX_FOR_FILE_PATH
                            Add an additional prefix to the file path.


Documentation of the iterator selection probability script is [here](./docs/data_ratio_from_file.md)