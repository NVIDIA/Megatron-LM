# DeepSeek2-Lite è®­ç»ƒè„šæœ¬å‚æ•°åˆ†ææŠ¥å‘Š

## æ¦‚è¿°
æœ¬æŠ¥å‘Šåˆ†æäº† `train_deepseek2_lite_h100_fp8.sh` è„šæœ¬åœ¨ `transformer-impl local` æ¨¡å¼ä¸‹çš„å‚æ•°é…ç½®å’Œå…¼å®¹æ€§é—®é¢˜ã€‚

## å…³é”®å‘ç°

### 1. FP8 ä¸ transformer-impl local çš„å…¼å®¹æ€§

**é‡è¦å‘ç°ï¼šFP8 ä¸æ”¯æŒ transformer-impl local**

æ ¹æ®ä»£ç åˆ†æï¼ˆ`megatron/legacy/model/transformer.py:1439`ï¼‰ï¼š
```python
assert args.transformer_impl == 'transformer_engine', \
    'transformer-engine required for fp8 training and inference'
```

**ç»“è®ºï¼š**
- âœ… å½“å‰è„šæœ¬è®¾ç½® `DTYPE="bf16"`ï¼Œä¸ `--transformer-impl local` **å…¼å®¹**
- âŒ å¦‚æœå¯ç”¨ FP8 (`DTYPE="fp8"`)ï¼Œå¿…é¡»ä½¿ç”¨ `--transformer-impl transformer_engine`
- âš ï¸ è„šæœ¬åç§°åŒ…å« "fp8"ï¼Œä½†å®é™…ä½¿ç”¨çš„æ˜¯ bf16ï¼Œè¿™å¯èƒ½å¯¼è‡´æ··æ·†

### 2. Multi-Latent Attention (MLA) æ”¯æŒ

**âœ… MLA å®Œå…¨æ”¯æŒ transformer-impl local**

ä» `megatron/core/models/gpt/gpt_layer_specs.py` çš„ `get_gpt_layer_local_spec` å‡½æ•°å¯ä»¥çœ‹åˆ°ï¼ŒMLA å‚æ•°åœ¨ local å®ç°ä¸­å®Œå…¨æ”¯æŒï¼š
- `--multi-latent-attention` âœ…
- `--kv-lora-rank` âœ…
- `--v-head-dim` âœ…
- `--qk-head-dim` âœ…
- `--qk-layernorm` âœ…
- `--qk-pos-emb-head-dim` âœ…

### 3. Mixture of Experts (MoE) æ”¯æŒ

**âœ… MoE æ”¯æŒ transformer-impl local**

MoE ç›¸å…³å‚æ•°åœ¨ local å®ç°ä¸­å‡æ”¯æŒï¼š
- `--num-experts` âœ…
- `--moe-layer-freq` âœ…
- `--moe-ffn-hidden-size` âœ…
- `--moe-grouped-gemm` âœ…
- å…¶ä»– MoE å‚æ•° âœ…

### 4. å…¶ä»–å‚æ•°æ£€æŸ¥

#### å·²æ­£ç¡®é…ç½®çš„å‚æ•°ï¼š
- âœ… `--use-mcore-models` - å¿…éœ€ï¼Œç”¨äºå¯ç”¨ MCore æ¶æ„
- âœ… `--normalization RMSNorm` - æ”¯æŒ
- âœ… `--swiglu` - æ”¯æŒ
- âœ… `--position-embedding-type rope` - æ”¯æŒ
- âœ… `--no-rope-fusion` - ä¸ MLA å…¼å®¹
- âœ… `--sequence-parallel` - æ”¯æŒ
- âœ… `--attention-softmax-in-fp32` - æ”¯æŒ

#### éœ€è¦æ³¨æ„çš„å‚æ•°ï¼š
- âš ï¸ `--attention-backend` - è„šæœ¬ä¸­æœªæ˜¾å¼è®¾ç½®ï¼Œé»˜è®¤ä½¿ç”¨ `auto`
  - å½“ `transformer-impl=local` æ—¶ï¼Œå»ºè®®æ˜¾å¼è®¾ç½® `--attention-backend local` æˆ– `--attention-backend unfused`
  - å¯é€‰å€¼ï¼š`flash`, `fused`, `unfused`, `local`, `auto`

### 5. è®­ç»ƒå‚æ•°æ£€æŸ¥

#### ä¼˜åŒ–å™¨å‚æ•°ï¼š
- âœ… `--decoupled-lr` å’Œ `--decoupled-min-lr` - æ”¯æŒ decoupled AdamW
- âœ… `--bf16` - ä¸ local å®ç°å…¼å®¹
- âœ… `--grad-reduce-in-bf16` - æ”¯æŒ

#### åˆ†å¸ƒå¼è®­ç»ƒå‚æ•°ï¼š
- âœ… `--use-distributed-optimizer` - æ”¯æŒ
- âœ… `--overlap-grad-reduce` - æ”¯æŒ
- âœ… `--overlap-param-gather` - æ”¯æŒ

## å‚æ•°é…ç½®å»ºè®®

### å½“å‰é…ç½®ï¼ˆbf16 + localï¼‰âœ…
```bash
DTYPE="bf16"
--transformer-impl local
```
**çŠ¶æ€ï¼š** å®Œå…¨å…¼å®¹ï¼Œå¯ä»¥æ­£å¸¸è¿è¡Œ

### å¦‚æœè¦ä½¿ç”¨ FP8 âš ï¸
```bash
DTYPE="fp8"
--transformer-impl transformer_engine  # å¿…é¡»æ”¹ä¸º transformer_engine
```
**æ³¨æ„ï¼š** éœ€è¦ä¿®æ”¹è„šæœ¬ï¼Œå°† `--transformer-impl local` æ”¹ä¸º `--transformer-impl transformer_engine`

### æ¨èçš„æ”¹è¿›

1. **æ˜¾å¼è®¾ç½® attention-backend**ï¼ˆå¯é€‰ä½†æ¨èï¼‰ï¼š
   ```bash
   --attention-backend local  # æˆ– unfused
   ```

2. **è„šæœ¬å‘½åå»ºè®®**ï¼š
   - å½“å‰è„šæœ¬ä½¿ç”¨ bf16ï¼Œä½†åç§°åŒ…å« "fp8"ï¼Œå»ºè®®é‡å‘½åæˆ–æ·»åŠ æ³¨é‡Šè¯´æ˜

3. **å‚æ•°éªŒè¯**ï¼š
   - æ·»åŠ è¿è¡Œæ—¶æ£€æŸ¥ï¼Œç¡®ä¿ DTYPE å’Œ transformer-impl å…¼å®¹

## è¿è¡Œ deepseek2_lite è®­ç»ƒçš„æ­¥éª¤

### ä½¿ç”¨ bf16 + localï¼ˆå½“å‰é…ç½®ï¼‰âœ…

1. **ç¡®ä¿å‚æ•°è®¾ç½®æ­£ç¡®**ï¼š
   ```bash
   DTYPE="bf16"
   --transformer-impl local
   ```

2. **æ£€æŸ¥ä¾èµ–**ï¼š
   - âœ… PyTorch
   - âœ… CUDA
   - âœ… ä¸éœ€è¦ Transformer Engineï¼ˆä½¿ç”¨ local å®ç°ï¼‰

3. **è¿è¡Œè®­ç»ƒ**ï¼š
   ```bash
   bash examples/deepseek2_lite/train_deepseek2_lite_h100_fp8.sh \
       checkpoints/deepseek2_lite \
       tensorboard_logs/deepseek2_lite \
       model/deepseek2_lite \
       dataset/wikitext_processed/wikitext_processed_text_document
   ```

### ä½¿ç”¨ FP8ï¼ˆéœ€è¦ä¿®æ”¹ï¼‰âš ï¸

1. **ä¿®æ”¹è„šæœ¬**ï¼š
   - å°† `DTYPE="bf16"` æ”¹ä¸º `DTYPE="fp8"`
   - å°† `--transformer-impl local` æ”¹ä¸º `--transformer-impl transformer_engine`

2. **æ£€æŸ¥ä¾èµ–**ï¼š
   - âœ… PyTorch
   - âœ… CUDA
   - âœ… **Transformer Engine**ï¼ˆå¿…éœ€ï¼‰

3. **è¿è¡Œè®­ç»ƒ**ï¼š
   ```bash
   bash examples/deepseek2_lite/train_deepseek2_lite_h100_fp8.sh ...
   ```

## æ€»ç»“

### âœ… å½“å‰é…ç½®çŠ¶æ€
- **å…¼å®¹æ€§ï¼š** å®Œå…¨å…¼å®¹
- **MLAï¼š** æ”¯æŒ
- **MoEï¼š** æ”¯æŒ
- **æ•°æ®ç±»å‹ï¼š** bf16ï¼ˆä¸ local å…¼å®¹ï¼‰

### âš ï¸ æ³¨æ„äº‹é¡¹
1. è„šæœ¬åç§°æš—ç¤ºä½¿ç”¨ FP8ï¼Œä½†å®é™…ä½¿ç”¨ bf16
2. å¦‚æœå°†æ¥è¦å¯ç”¨ FP8ï¼Œå¿…é¡»åˆ‡æ¢åˆ° transformer_engine
3. å»ºè®®æ˜¾å¼è®¾ç½® `--attention-backend` å‚æ•°

### ğŸ“ å»ºè®®çš„ä¿®æ”¹
1. åœ¨è„šæœ¬ä¸­æ·»åŠ å‚æ•°éªŒè¯é€»è¾‘
2. æ›´æ–°è„šæœ¬æ³¨é‡Šï¼Œè¯´æ˜å½“å‰ä½¿ç”¨ bf16
3. è€ƒè™‘æ·»åŠ  `--attention-backend local` å‚æ•°

