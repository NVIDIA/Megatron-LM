# quant_cy_npu - NPU Quantization Operators for 910B

é«˜æ€§èƒ½çš„NPUé‡åŒ–ç®—å­åº“ï¼Œä¸“ä¸ºAscend 910Bç¯å¢ƒä¼˜åŒ–ï¼Œæ”¯æŒå¤šç§é‡åŒ–æ ¼å¼ã€‚

## ğŸš€ æ”¯æŒçš„é‡åŒ–æ ¼å¼

- **HiF8**: 8ä½æ··åˆç²¾åº¦æµ®ç‚¹é‡åŒ–
- **HiF4**: 4ä½æ··åˆç²¾åº¦æµ®ç‚¹é‡åŒ– (hifx4_v12)
- **MXFP4**: 4ä½MXæµ®ç‚¹é‡åŒ–
- **MXFP8**: 8ä½MXæµ®ç‚¹é‡åŒ– (E4M3/E5M2)
- **NVF4**: 4ä½NVæµ®ç‚¹é‡åŒ–

## ğŸ“‹ ç¯å¢ƒè¦æ±‚

- **ç¡¬ä»¶**: Ascend 910B NPU
- **è½¯ä»¶**: 
  - Python 3.7+
  - PyTorch 1.8+
  - torch_npu (é€‚é…910Bç‰ˆæœ¬)
  - Ascend-CANN-toolkit (910Bç‰ˆæœ¬)

## ğŸ”§ å®‰è£…å’Œç¼–è¯‘

### 1. ç¯å¢ƒæ£€æŸ¥

ç¡®ä¿æ‚¨çš„ç¯å¢ƒæ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š

```bash
# æ£€æŸ¥torch_npu
python3 -c "import torch_npu; print('torch_npu version:', torch_npu.__version__)"

# æ£€æŸ¥NPUè®¾å¤‡
python3 -c "import torch_npu; print('NPU devices:', torch_npu.npu.device_count())"

# æ£€æŸ¥Ascendå·¥å…·é“¾
ls /usr/local/Ascend/ascend-toolkit/latest/
```

### 2. ç¼–è¯‘å®‰è£…

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd quant/quant_cy_npu

# è¿è¡Œæ„å»ºè„šæœ¬
./build.sh
```

æ„å»ºè„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- æ£€æŸ¥ç¯å¢ƒä¾èµ–
- æ¸…ç†ä¹‹å‰çš„æ„å»º
- ç¼–è¯‘NPUç®—å­
- æµ‹è¯•å®‰è£…

### 3. æ‰‹åŠ¨ç¼–è¯‘ï¼ˆå¯é€‰ï¼‰

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export ASCEND_OPP_PATH=/usr/local/Ascend/ascend-toolkit/latest/opp
export PATH=/usr/local/Ascend/ascend-toolkit/latest/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/Ascend/ascend-toolkit/latest/lib64:$LD_LIBRARY_PATH

# ç¼–è¯‘
python3 setup.py build_ext --inplace
```

## ğŸ“– ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ç”¨æ³•

```python
import torch
import torch_npu
import quant_cy_npu
from quant_cy_npu import QType, quant_dequant_float

# æ£€æŸ¥NPUç®—å­çŠ¶æ€
quant_cy_npu.print_status()

# åˆ›å»ºæµ‹è¯•å¼ é‡
x = torch.randn(1024, 1024).npu()  # ç§»åŠ¨åˆ°NPU

# å®šä¹‰é‡åŒ–ç±»å‹
qtype = QType('hif8')  # æˆ– 'hifx4_v12', 'mxfp4', 'mxfp8e4m3' ç­‰

# æ‰§è¡Œé‡åŒ–-åé‡åŒ–
y = quant_dequant_float(x, qtype)

print(f"Input shape: {x.shape}")
print(f"Output shape: {y.shape}")
print(f"Quantization error: {torch.norm(x - y).item():.6f}")
```

### æ”¯æŒçš„é‡åŒ–ç±»å‹

```python
# HiF8é‡åŒ–
qtype_hif8 = QType('hif8')

# HiF4é‡åŒ– (v12ç‰ˆæœ¬)
qtype_hif4 = QType('hifx4_v12')

# MXFP4é‡åŒ–
qtype_mxfp4 = QType('mxfp4')

# MXFP8 E4M3é‡åŒ–
qtype_mxfp8_e4m3 = QType('mxfp8e4m3')

# MXFP8 E5M2é‡åŒ–
qtype_mxfp8_e5m2 = QType('mxfp8e5m2')

# NVF4é‡åŒ–
qtype_nvf4 = QType('nvf4')
```

### é«˜çº§ç”¨æ³•

```python
# æŒ‡å®šé‡åŒ–ç»´åº¦
qtype = QType('hif8').dim(-1)  # åœ¨æœ€åä¸€ä¸ªç»´åº¦è¿›è¡Œé‡åŒ–

# æ‰¹é‡å¤„ç†
batch_size = 8
x = torch.randn(batch_size, 1024, 1024).npu()
y = quant_dequant_float(x, qtype)

# æ€§èƒ½æµ‹è¯•
import time

def benchmark_quantization(x, qtype, iterations=100):
    torch_npu.npu.synchronize()
    start_time = time.time()
    
    for _ in range(iterations):
        y = quant_dequant_float(x, qtype)
        torch_npu.npu.synchronize()
    
    end_time = time.time()
    avg_time = (end_time - start_time) / iterations
    return avg_time

# æµ‹è¯•ä¸åŒé‡åŒ–æ ¼å¼çš„æ€§èƒ½
formats = ['hif8', 'hifx4_v12', 'mxfp4', 'mxfp8e4m3']
x = torch.randn(1024, 1024).npu()

for fmt in formats:
    qtype = QType(fmt)
    avg_time = benchmark_quantization(x, qtype)
    print(f"{fmt}: {avg_time*1000:.2f}ms")
```

## ğŸ—ï¸ æ¶æ„è¯´æ˜

### æ ¸å¿ƒç»„ä»¶

1. **QType**: é‡åŒ–ç±»å‹å®šä¹‰å’Œå‚æ•°ç®¡ç†
2. **QTensor**: é‡åŒ–å¼ é‡å°è£…
3. **NPUç®—å­**: é«˜æ€§èƒ½çš„C++/CUDAç®—å­å®ç°
4. **Pythonæ¥å£**: ç”¨æˆ·å‹å¥½çš„Python API

### æ–‡ä»¶ç»“æ„

```
quant_cy_npu/
â”œâ”€â”€ setup.py                 # æ„å»ºé…ç½®
â”œâ”€â”€ build.sh                 # æ„å»ºè„šæœ¬
â”œâ”€â”€ README.md               # è¯´æ˜æ–‡æ¡£
â””â”€â”€ quant_cy_npu/
    â”œâ”€â”€ __init__.py         # ä¸»æ¨¡å—
    â””â”€â”€ base/
        â”œâ”€â”€ QType.py        # é‡åŒ–ç±»å‹å®šä¹‰
        â”œâ”€â”€ QTensor.py      # é‡åŒ–å¼ é‡
        â”œâ”€â”€ QFunc/          # é‡åŒ–å‡½æ•°
        â”‚   â”œâ”€â”€ quant_basic.py
        â”‚   â”œâ”€â”€ hif8.py
        â”‚   â””â”€â”€ hifx.py
        â””â”€â”€ cusrc/          # NPUç®—å­æºç 
            â”œâ”€â”€ npu_quant.cpp
            â”œâ”€â”€ hif8_quant_op.h
            â”œâ”€â”€ mxfp4_quant_op.h
            â””â”€â”€ tensorutils.h
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ç¼–è¯‘å¤±è´¥**
   ```bash
   # æ£€æŸ¥Ascendå·¥å…·é“¾ç‰ˆæœ¬
   cat /usr/local/Ascend/ascend-toolkit/latest/version.info
   
   # æ£€æŸ¥ç¯å¢ƒå˜é‡
   echo $ASCEND_OPP_PATH
   echo $LD_LIBRARY_PATH
   ```

2. **NPUç®—å­ä¸å¯ç”¨**
   ```python
   import quant_cy_npu
   print(quant_cy_npu.NPU_OPS_AVAILABLE)  # åº”è¯¥ä¸ºTrue
   ```

3. **å†…å­˜ä¸è¶³**
   ```python
   # å‡å°æ‰¹æ¬¡å¤§å°
   x = torch.randn(512, 512).npu()  # è€Œä¸æ˜¯ 1024x1024
   ```

### è°ƒè¯•æ¨¡å¼

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# æ£€æŸ¥ç®—å­çŠ¶æ€
quant_cy_npu.print_status()
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

åœ¨910Bç¯å¢ƒä¸‹çš„å…¸å‹æ€§èƒ½è¡¨ç°ï¼š

| é‡åŒ–æ ¼å¼ | è¾“å…¥å¤§å° | å¹³å‡å»¶è¿Ÿ | å†…å­˜èŠ‚çœ |
|----------|----------|----------|----------|
| HiF8     | 1024x1024| 0.15ms   | 75%      |
| HiF4     | 1024x1024| 0.12ms   | 87.5%    |
| MXFP4    | 1024x1024| 0.18ms   | 87.5%    |
| MXFP8    | 1024x1024| 0.16ms   | 75%      |

*æ³¨ï¼šå®é™…æ€§èƒ½å¯èƒ½å› ç¡¬ä»¶é…ç½®å’Œè½¯ä»¶ç‰ˆæœ¬è€Œå¼‚*

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ã€‚

## ğŸ“„ è®¸å¯è¯

Apache License 2.0
