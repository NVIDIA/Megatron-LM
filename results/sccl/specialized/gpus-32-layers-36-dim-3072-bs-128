Warning: Permanently added '[192.168.0.71]:43529' (ECDSA) to the list of known hosts.
Warning: Permanently added '[192.168.0.34]:45820' (ECDSA) to the list of known hosts.
Warning: Permanently added '[192.168.0.87]:46844' (ECDSA) to the list of known hosts.
[1,28]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,28]<stdout>:Detected CUDA files, patching ldflags
[1,28]<stdout>:Emitting ninja build file /home/amawa/.cache/torch_extensions/transformer_inference/build.ninja...
[1,28]<stdout>:Building extension module transformer_inference...
[1,28]<stdout>:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1,28]<stdout>:ninja: no work to do.
[1,28]<stdout>:Loading extension module transformer_inference...
[1,28]<stdout>:Time to load transformer_inference op: 0.22391057014465332 seconds
[1,24]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,25]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,24]<stdout>:Detected CUDA files, patching ldflags
[1,24]<stdout>:Emitting ninja build file /home/amawa/.cache/torch_extensions/transformer_inference/build.ninja...
[1,26]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,24]<stdout>:Building extension module transformer_inference...
[1,24]<stdout>:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1,29]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,30]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,31]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,27]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,24]<stdout>:ninja: no work to do.
[1,24]<stdout>:Loading extension module transformer_inference...
[1,24]<stdout>:Time to load transformer_inference op: 0.3375215530395508 seconds
[1,25]<stdout>:Loading extension module transformer_inference...
[1,25]<stdout>:Time to load transformer_inference op: 0.28804564476013184 seconds
[1,26]<stdout>:Loading extension module transformer_inference...
[1,26]<stdout>:Time to load transformer_inference op: 0.27498316764831543 seconds
[1,29]<stdout>:Loading extension module transformer_inference...
[1,29]<stdout>:Time to load transformer_inference op: 0.2606651782989502 seconds
[1,30]<stdout>:Loading extension module transformer_inference...
[1,30]<stdout>:Time to load transformer_inference op: 0.24644184112548828 seconds
[1,31]<stdout>:Loading extension module transformer_inference...
[1,31]<stdout>:Time to load transformer_inference op: 0.2285020351409912 seconds
[1,27]<stdout>:Loading extension module transformer_inference...
[1,27]<stdout>:Time to load transformer_inference op: 0.2187671661376953 seconds
[1,28]<stdout>:[2021-12-09 02:24:03,298] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,5]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,3]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,24]<stdout>:[2021-12-09 02:24:03,439] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,4]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,25]<stdout>:[2021-12-09 02:24:03,456] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,2]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,5]<stdout>:Detected CUDA files, patching ldflags
[1,5]<stdout>:Emitting ninja build file /home/amawa/.cache/torch_extensions/transformer_inference/build.ninja...
[1,26]<stdout>:[2021-12-09 02:24:03,476] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,0]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,29]<stdout>:[2021-12-09 02:24:03,492] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,6]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,30]<stdout>:[2021-12-09 02:24:03,506] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,1]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,7]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,31]<stdout>:[2021-12-09 02:24:03,517] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,27]<stdout>:[2021-12-09 02:24:03,517] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,18]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,22]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,16]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,5]<stdout>:Building extension module transformer_inference...
[1,5]<stdout>:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1,17]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,19]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,20]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,23]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,21]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,5]<stdout>:ninja: no work to do.
[1,5]<stdout>:Loading extension module transformer_inference...
[1,2]<stdout>:Loading extension module transformer_inference...
[1,2]<stdout>:Time to load transformer_inference op: 0.3976399898529053 seconds
[1,5]<stdout>:Time to load transformer_inference op: 0.4906485080718994 seconds
[1,0]<stdout>:Loading extension module transformer_inference...
[1,0]<stdout>:Time to load transformer_inference op: 0.3706200122833252 seconds
[1,6]<stdout>:Loading extension module transformer_inference...
[1,6]<stdout>:Time to load transformer_inference op: 0.349179744720459 seconds
[1,1]<stdout>:Loading extension module transformer_inference...
[1,1]<stdout>:Time to load transformer_inference op: 0.3388686180114746 seconds
[1,7]<stdout>:Loading extension module transformer_inference...
[1,7]<stdout>:Time to load transformer_inference op: 0.33177757263183594 seconds
[1,3]<stdout>:Loading extension module transformer_inference...
[1,3]<stdout>:Time to load transformer_inference op: 0.5216670036315918 seconds
[1,4]<stdout>:Loading extension module transformer_inference...
[1,4]<stdout>:Time to load transformer_inference op: 0.5081439018249512 seconds
[1,14]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,8]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,13]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,14]<stdout>:Detected CUDA files, patching ldflags
[1,14]<stdout>:Emitting ninja build file /home/amawa/.cache/torch_extensions/transformer_inference/build.ninja...
[1,14]<stdout>:Building extension module transformer_inference...
[1,14]<stdout>:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1,9]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,15]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,10]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,11]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,14]<stdout>:ninja: no work to do.
[1,12]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,14]<stdout>:Loading extension module transformer_inference...
[1,14]<stdout>:Time to load transformer_inference op: 0.37073326110839844 seconds
[1,13]<stdout>:Loading extension module transformer_inference...
[1,13]<stdout>:Time to load transformer_inference op: 0.304290771484375 seconds
[1,9]<stdout>:Loading extension module transformer_inference...
[1,9]<stdout>:Time to load transformer_inference op: 0.28691697120666504 seconds
[1,0]<stdout>:using world size: 32, data-parallel-size: 32, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
[1,0]<stdout>:WARNING: overriding default arguments for tokenizer_type:GPT2BPETokenizer                        with tokenizer_type:GPT2BPETokenizer
[1,0]<stdout>:setting global batch size to 4096
[1,0]<stdout>:using torch.float16 for parameters ...
[1,0]<stdout>:------------------------ arguments ------------------------
[1,0]<stdout>:  accumulate_allreduce_grads_in_fp32 .............. False
[1,0]<stdout>:  adam_beta1 ...................................... 0.9
[1,0]<stdout>:  adam_beta2 ...................................... 0.999
[1,0]<stdout>:  adam_eps ........................................ 1e-08
[1,0]<stdout>:  adlr_autoresume ................................. False
[1,0]<stdout>:  adlr_autoresume_interval ........................ 1000
[1,0]<stdout>:  apply_query_key_layer_scaling ................... True
[1,0]<stdout>:  apply_residual_connection_post_layernorm ........ False
[1,0]<stdout>:  attention_dropout ............................... 0.1
[1,0]<stdout>:  attention_softmax_in_fp32 ....................... False
[1,0]<stdout>:  bert_binary_head ................................ True
[1,0]<stdout>:  bert_load ....................................... None
[1,0]<stdout>:  bf16 ............................................ False
[1,0]<stdout>:  bias_dropout_fusion ............................. True
[1,0]<stdout>:  bias_gelu_fusion ................................ True
[1,0]<stdout>:  biencoder_projection_dim ........................ 0
[1,0]<stdout>:  biencoder_shared_query_context_model ............ False
[1,0]<stdout>:  block_data_path ................................. None
[1,0]<stdout>:  checkpoint_activations .......................... False
[1,0]<stdout>:  checkpoint_in_cpu ............................... False
[1,0]<stdout>:  checkpoint_num_layers ........................... 1
[1,0]<stdout>:  clip_grad ....................................... 1.0
[1,0]<stdout>:  consumed_train_samples .......................... 0
[1,0]<stdout>:  consumed_train_tokens ........................... 0
[1,0]<stdout>:  consumed_valid_samples .......................... 0
[1,0]<stdout>:  contigious_checkpointing ........................ False
[1,0]<stdout>:  cpu_optimizer ................................... False[1,0]<stdout>:
[1,0]<stdout>:  cpu_torch_adam .................................. False
[1,0]<stdout>:  curriculum_learning ............................. False
[1,0]<stdout>:  data_impl ....................................... infer
[1,0]<stdout>:  data_parallel_size .............................. 32
[1,0]<stdout>:  data_path ....................................... None
[1,0]<stdout>:  dataloader_type ................................. single
[1,0]<stdout>:  DDP_impl ........................................ local
[1,0]<stdout>:  decoder_seq_length .............................. None
[1,0]<stdout>:  deepscale ....................................... False
[1,0]<stdout>:  deepscale_config ................................ None
[1,0]<stdout>:  deepspeed ....................................... True[1,0]<stdout>:
[1,0]<stdout>:  deepspeed_activation_checkpointing .............. False
[1,0]<stdout>:  deepspeed_config ................................ None
[1,0]<stdout>:  deepspeed_mpi ................................... False
[1,0]<stdout>:  distribute_checkpointed_activations ............. False
[1,0]<stdout>:  distributed_backend ............................. nccl
[1,0]<stdout>:  ds_inference .................................... True
[1,0]<stdout>:  embedding_path .................................. None
[1,0]<stdout>:  encoder_seq_length .............................. 30
[1,0]<stdout>:  eod_mask_loss ................................... False
[1,0]<stdout>:  eval_interval ................................... 1000
[1,0]<stdout>:  eval_iters ...................................... 100
[1,0]<stdout>:  evidence_data_path .............................. None
[1,0]<stdout>:  exit_duration_in_mins ........................... None
[1,0]<stdout>:  exit_interval ................................... None
[1,0]<stdout>:  expert_interval ................................. 2
[1,0]<stdout>:  ffn_hidden_size ................................. 12288
[1,0]<stdout>:  finetune ........................................ False
[1,0]<stdout>:  fp16 ............................................ True
[1,0]<stdout>:  fp16_lm_cross_entropy ........................... False[1,0]<stdout>:
[1,0]<stdout>:  fp32_residual_connection ........................ False
[1,0]<stdout>:  genfile ......................................... unconditional_samples.json
[1,0]<stdout>:  global_batch_size ............................... 4096
[1,0]<stdout>:  greedy .......................................... False
[1,0]<stdout>:  hidden_dropout .................................. 0.1
[1,0]<stdout>:  hidden_size ..................................... 3072
[1,0]<stdout>:  hysteresis ...................................... 2
[1,0]<stdout>:  ict_head_size ................................... None
[1,0]<stdout>:  ict_load ........................................ None[1,0]<stdout>:
[1,0]<stdout>:  img_dim ......................................... 224
[1,0]<stdout>:  indexer_batch_size .............................. 128
[1,0]<stdout>:  indexer_log_interval ............................ 1000
[1,0]<stdout>:  init_method_std ................................. 0.02
[1,0]<stdout>:  init_method_xavier_uniform ...................... False
[1,0]<stdout>:  initial_loss_scale .............................. 4294967296
[1,0]<stdout>:  kv_channels ..................................... 96
[1,0]<stdout>:  layernorm_epsilon ............................... 1e-05[1,0]<stdout>:
[1,0]<stdout>:  lazy_mpu_init ................................... None
[1,0]<stdout>:  load ............................................ checkpoints/gpt2_345m
[1,0]<stdout>:  local_rank ...................................... None
[1,0]<stdout>:  log_batch_size_to_tensorboard ................... False
[1,0]<stdout>:  log_interval .................................... 1
[1,0]<stdout>:  log_learning_rate_to_tensorboard ................ True
[1,0]<stdout>:  log_loss_scale_to_tensorboard ................... True
[1,0]<stdout>:  log_num_zeros_in_grad ........................... False
[1,0]<stdout>:  log_params_norm ................................. False
[1,0]<stdout>:  log_timers_to_tensorboard ....................... False[1,0]<stdout>:
[1,0]<stdout>:  log_validation_ppl_to_tensorboard ............... False[1,0]<stdout>:
[1,0]<stdout>:  loss_scale ...................................... None
[1,0]<stdout>:  loss_scale_window ............................... 1000
[1,0]<stdout>:  lr .............................................. None
[1,0]<stdout>:  lr_decay_iters .................................. None
[1,0]<stdout>:  lr_decay_samples ................................ None
[1,0]<stdout>:  lr_decay_style .................................. linear
[1,0]<stdout>:  lr_decay_tokens ................................. None
[1,0]<stdout>:  lr_warmup_fraction .............................. None
[1,0]<stdout>:  lr_warmup_iters ................................. 0
[1,0]<stdout>:  lr_warmup_samples ............................... 0
[1,0]<stdout>:  make_vocab_size_divisible_by .................... 128
[1,0]<stdout>:  mask_prob ....................................... 0.15
[1,0]<stdout>:  masked_softmax_fusion ........................... True
[1,0]<stdout>:  max_position_embeddings ......................... 1024
[1,0]<stdout>:  memory_centric_tiled_linear ..................... False
[1,0]<stdout>:  merge_file ...................................... gpt2-merges.txt
[1,0]<stdout>:  micro_batch_size ................................ 128
[1,0]<stdout>:  min_loss_scale .................................. 1.0
[1,0]<stdout>:  min_lr .......................................... 0.0
[1,0]<stdout>:  mmap_warmup ..................................... False
[1,0]<stdout>:  moe_eval_capacity_factor ........................ 1.0[1,0]<stdout>:
[1,0]<stdout>:  moe_min_capacity ................................ 4
[1,0]<stdout>:  moe_token_dropping .............................. True
[1,0]<stdout>:  moe_train_capacity_factor ....................... 1.0
[1,0]<stdout>:  no_load_optim ................................... True
[1,0]<stdout>:  no_load_rng ..................................... True
[1,0]<stdout>:  no_save_optim ................................... None
[1,0]<stdout>:  no_save_rng ..................................... None
[1,0]<stdout>:  num_attention_heads ............................. 32[1,0]<stdout>:
[1,0]<stdout>:  num_channels .................................... 3
[1,0]<stdout>:  num_classes ..................................... 1000
[1,0]<stdout>:  num_experts ..................................... 128
[1,0]<stdout>:  num_layers ...................................... 36
[1,0]<stdout>:  num_layers_per_virtual_pipeline_stage ........... None
[1,0]<stdout>:  num_samples ..................................... 2560
[1,0]<stdout>:  num_workers ..................................... 2
[1,0]<stdout>:  onnx_safe ....................................... None
[1,0]<stdout>:  openai_gelu ..................................... False
[1,0]<stdout>:  optimizer ....................................... adam
[1,0]<stdout>:  out_seq_length .................................. 30
[1,0]<stdout>:  override_lr_scheduler ........................... False[1,0]<stdout>:
[1,0]<stdout>:  params_dtype .................................... torch.float16
[1,0]<stdout>:  partition_activations ........................... False[1,0]<stdout>:
[1,0]<stdout>:  patch_dim ....................................... 16
[1,0]<stdout>:  pipeline_model_parallel_size .................... 1
[1,0]<stdout>:  profile_backward ................................ False
[1,0]<stdout>:  query_in_block_prob ............................. 0.1
[1,0]<stdout>:  rampup_batch_size ............................... None
[1,0]<stdout>:  rank ............................................ 0
[1,0]<stdout>:  recompute ....................................... False
[1,0]<stdout>:  remote_device ................................... none
[1,0]<stdout>:  reset_attention_mask ............................ False
[1,0]<stdout>:  reset_position_ids .............................. False
[1,0]<stdout>:  retriever_report_topk_accuracies ................ []
[1,0]<stdout>:  retriever_score_scaling ......................... False
[1,0]<stdout>:  retriever_seq_length ............................ 256[1,0]<stdout>:
[1,0]<stdout>:  sample_input_file ............................... None
[1,0]<stdout>:  sample_output_file .............................. None
[1,0]<stdout>:  sample_rate ..................................... 1.0
[1,0]<stdout>:  save ............................................ None
[1,0]<stdout>:  save_interval ................................... None
[1,0]<stdout>:  scatter_gather_tensors_in_pipeline .............. True
[1,0]<stdout>:  scattered_embeddings ............................ False
[1,0]<stdout>:  seed ............................................ 1234[1,0]<stdout>:
[1,0]<stdout>:  seq_length ...................................... 30
[1,0]<stdout>:  sgd_momentum .................................... 0.9
[1,0]<stdout>:  short_seq_prob .................................. 0.1
[1,0]<stdout>:  split ........................................... 969, 30, 1
[1,0]<stdout>:  split_transformers .............................. False
[1,0]<stdout>:  synchronize_each_layer .......................... False[1,0]<stdout>:
[1,0]<stdout>:  temperature ..................................... 1.0
[1,0]<stdout>:  tensor_model_parallel_size ...................... 1
[1,0]<stdout>:  tensorboard_dir ................................. None
[1,0]<stdout>:  tensorboard_log_interval ........................ 1
[1,0]<stdout>:  tensorboard_queue_size .......................... 1000
[1,0]<stdout>:  tile_factor ..................................... 1
[1,0]<stdout>:  titles_data_path ................................ None
[1,0]<stdout>:  tokenizer_type .................................. GPT2BPETokenizer
[1,0]<stdout>:  top_k ........................................... 0
[1,0]<stdout>:  top_p ........................................... 0.9
[1,0]<stdout>:  topk ............................................ 1
[1,0]<stdout>:  train_iters ..................................... None
[1,0]<stdout>:  train_samples ................................... None
[1,0]<stdout>:  train_tokens .................................... None
[1,0]<stdout>:  use_checkpoint_lr_scheduler ..................... False
[1,0]<stdout>:  use_contiguous_buffers_in_ddp ................... False
[1,0]<stdout>:  use_cpu_initialization .......................... None
[1,0]<stdout>:  use_one_sent_docs ............................... False
[1,0]<stdout>:  use_pin_memory .................................. False
[1,0]<stdout>:  virtual_pipeline_model_parallel_size ............ None
[1,0]<stdout>:  vocab_extra_ids ................................. 0
[1,0]<stdout>:  vocab_file ...................................... gpt2-vocab.json[1,0]<stdout>:
[1,0]<stdout>:  weight_decay .................................... 0.01
[1,0]<stdout>:  world_size ...................................... 32
[1,0]<stdout>:  zero_allgather_bucket_size ...................... 0.0
[1,0]<stdout>:  zero_contigious_gradients ....................... False
[1,0]<stdout>:  zero_reduce_bucket_size ......................... 0.0
[1,0]<stdout>:  zero_reduce_scatter ............................. False
[1,0]<stdout>:  zero_stage ...................................... 1.0
[1,0]<stdout>:-------------------- end of arguments ---------------------
[1,0]<stdout>:setting number of micro-batches to constant 1
[1,0]<stdout>:> building GPT2BPETokenizer tokenizer ...
[1,15]<stdout>:Loading extension module transformer_inference...
[1,2]<stdout>:[2021-12-09 02:24:03,978] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,15]<stdout>:Time to load transformer_inference op: 0.24661540985107422 seconds
[1,10]<stdout>:Loading extension module transformer_inference...
[1,10]<stdout>:Time to load transformer_inference op: 0.2383406162261963 seconds
[1,5]<stdout>:[2021-12-09 02:24:03,989] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,11]<stdout>:Loading extension module transformer_inference...
[1,11]<stdout>:Time to load transformer_inference op: 0.2118690013885498 seconds
[1,12]<stdout>:Loading extension module transformer_inference...
[1,8]<stdout>:Loading extension module transformer_inference...
[1,6]<stdout>:[2021-12-09 02:24:04,008] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,12]<stdout>:Time to load transformer_inference op: 0.20360708236694336 seconds
[1,8]<stdout>:Time to load transformer_inference op: 0.41533708572387695 seconds
[1,0]<stdout>: > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
[1,0]<stdout>:> initializing torch distributed ...
[1,0]<stdout>:[2021-12-09 02:24:04,009] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,1]<stdout>:[2021-12-09 02:24:04,018] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,7]<stdout>:[2021-12-09 02:24:04,021] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,3]<stdout>:[2021-12-09 02:24:04,047] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,4]<stdout>:[2021-12-09 02:24:04,066] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,14]<stdout>:[2021-12-09 02:24:04,340] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,12]<stdout>:[2021-12-09 02:24:04,341] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,15]<stdout>:[2021-12-09 02:24:04,341] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,9]<stdout>:[2021-12-09 02:24:04,341] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,10]<stdout>:[2021-12-09 02:24:04,341] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,11]<stdout>:[2021-12-09 02:24:04,342] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,8]<stdout>:[2021-12-09 02:24:04,342] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,13]<stdout>:[2021-12-09 02:24:04,342] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,23]<stdout>:Loading extension module transformer_inference...
[1,21]<stdout>:Loading extension module transformer_inference...
[1,21]<stdout>:Time to load transformer_inference op: 3.1328248977661133 seconds
[1,23]<stdout>:Time to load transformer_inference op: 3.1469473838806152 seconds
[1,22]<stdout>:Loading extension module transformer_inference...
[1,22]<stdout>:Time to load transformer_inference op: 3.320129632949829 seconds
[1,16]<stdout>:Loading extension module transformer_inference...
[1,16]<stdout>:Time to load transformer_inference op: 3.3010897636413574 seconds
[1,17]<stdout>:Loading extension module transformer_inference...
[1,17]<stdout>:Time to load transformer_inference op: 3.2867438793182373 seconds
[1,19]<stdout>:Loading extension module transformer_inference...
[1,19]<stdout>:Time to load transformer_inference op: 3.2700095176696777 seconds
[1,20]<stdout>:Loading extension module transformer_inference...
[1,20]<stdout>:Time to load transformer_inference op: 3.2607181072235107 seconds
[1,18]<stdout>:Loading extension module transformer_inference...
[1,18]<stdout>:Time to load transformer_inference op: 3.4323055744171143 seconds
[1,17]<stdout>:[2021-12-09 02:24:07,099] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,16]<stdout>:[2021-12-09 02:24:07,099] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,20]<stdout>:[2021-12-09 02:24:07,099] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,21]<stdout>:[2021-12-09 02:24:07,100] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,19]<stdout>:[2021-12-09 02:24:07,100] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,23]<stdout>:[2021-12-09 02:24:07,100] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,18]<stdout>:[2021-12-09 02:24:07,100] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,22]<stdout>:[2021-12-09 02:24:07,101] [INFO] [distributed.py:36:init_distributed] Not using the DeepSpeed or torch.distributed launchers, attempting to detect MPI environment...
[1,1]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=1, local_rank=1, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,1]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,7]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=7, local_rank=7, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,6]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=6, local_rank=6, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,2]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=2, local_rank=2, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,5]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=5, local_rank=5, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,4]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=4, local_rank=4, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,6]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,7]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,2]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,5]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,3]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=3, local_rank=3, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,4]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,0]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,0]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,3]<stdout>:[2021-12-09 02:24:07,136] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,20]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=20, local_rank=4, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,17]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=17, local_rank=1, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,17]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,13]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=13, local_rank=5, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,13]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,18]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=18, local_rank=2, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,18]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,14]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=14, local_rank=6, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,14]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,22]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=22, local_rank=6, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,22]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,9]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=9, local_rank=1, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,9]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,21]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=21, local_rank=5, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,21]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,8]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=8, local_rank=0, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,8]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,20]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,12]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=12, local_rank=4, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,12]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,23]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=23, local_rank=7, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,23]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,15]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=15, local_rank=7, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,19]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=19, local_rank=3, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,19]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,16]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=16, local_rank=0, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,16]<stdout>:[2021-12-09 02:24:07,132] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,10]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=10, local_rank=2, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,29]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=29, local_rank=5, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,11]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=11, local_rank=3, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,25]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=25, local_rank=1, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,25]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,15]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,27]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=27, local_rank=3, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,10]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,31]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=31, local_rank=7, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,31]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,11]<stdout>:[2021-12-09 02:24:07,134] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,30]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=30, local_rank=6, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,30]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,29]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,27]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,24]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=24, local_rank=0, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,24]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,28]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=28, local_rank=4, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,26]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:83:mpi_discovery] Discovered MPI settings of world_rank=26, local_rank=2, world_size=32, master_addr=192.168.0.78, master_port=29500
[1,26]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,28]<stdout>:[2021-12-09 02:24:07,135] [INFO] [distributed.py:46:init_distributed] Initializing torch distributed with backend: nccl
[1,0]<stdout>:> initializing tensor model parallel with size 1
[1,0]<stdout>:> initializing pipeline model parallel with size 1
[1,0]<stdout>:> setting random seeds to 1234 ...
[1,0]<stdout>:> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
[1,0]<stdout>:> compiling dataset index builder ...
[1,0]<stdout>:make: Entering directory '/home/amawa/moe-v2/Megatron-DeepSpeed/megatron/data'
[1,0]<stdout>:make: Nothing to be done for 'default'.
[1,0]<stdout>:make: Leaving directory '/home/amawa/moe-v2/Megatron-DeepSpeed/megatron/data'
[1,0]<stdout>:>>> done with dataset index builder. Compilation time: 0.093 seconds
[1,0]<stdout>:WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
[1,0]<stdout>:> compiling and loading fused kernels ...
[1,0]<stdout>:Detected CUDA files, patching ldflags
[1,0]<stdout>:Emitting ninja build file /home/amawa/moe-v2/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
[1,0]<stdout>:Building extension module scaled_upper_triang_masked_softmax_cuda...
[1,0]<stdout>:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1,0]<stdout>:ninja: no work to do.
[1,0]<stdout>:Loading extension module scaled_upper_triang_masked_softmax_cuda...
[1,0]<stdout>:Detected CUDA files, patching ldflags
[1,0]<stdout>:Emitting ninja build file /home/amawa/moe-v2/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
[1,0]<stdout>:Building extension module scaled_masked_softmax_cuda...
[1,0]<stdout>:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1,0]<stdout>:ninja: no work to do.
[1,0]<stdout>:Loading extension module scaled_masked_softmax_cuda...
[1,0]<stdout>:Detected CUDA files, patching ldflags
[1,0]<stdout>:Emitting ninja build file /home/amawa/moe-v2/Megatron-DeepSpeed/megatron/fused_kernels/build/build.ninja...
[1,0]<stdout>:Building extension module fused_mix_prec_layer_norm_cuda...
[1,0]<stdout>:Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1,0]<stdout>:ninja: no work to do.
[1,0]<stdout>:Loading extension module fused_mix_prec_layer_norm_cuda...
[1,0]<stdout>:NCCL version 2.8.4+cuda11.3
[1,0]<stdout>:>>> done with compiling and loading fused kernels. Compilation time: 18.094 seconds
[1,0]<stdout>:[2021-12-09 02:24:27,663] [INFO] [logging.py:69:log_dist] [Rank 0] initializing deepspeed groups
[1,0]<stdout>:[2021-12-09 02:24:27,663] [INFO] [logging.py:69:log_dist] [Rank 0] initializing deepspeed model parallel group with size 1
[1,0]<stdout>:[2021-12-09 02:24:27,992] [INFO] [logging.py:69:log_dist] [Rank 0] initializing deepspeed expert parallel group with size 32
[1,0]<stdout>:[2021-12-09 02:24:28,003] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [0]
[1,0]<stdout>:[2021-12-09 02:24:28,013] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [1]
[1,0]<stdout>:[2021-12-09 02:24:28,024] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [2]
[1,0]<stdout>:[2021-12-09 02:24:28,034] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [3]
[1,0]<stdout>:[2021-12-09 02:24:28,045] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [4]
[1,0]<stdout>:[2021-12-09 02:24:28,055] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [5]
[1,0]<stdout>:[2021-12-09 02:24:28,065] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [6]
[1,0]<stdout>:[2021-12-09 02:24:28,075] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [7]
[1,0]<stdout>:[2021-12-09 02:24:28,086] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [8]
[1,0]<stdout>:[2021-12-09 02:24:28,096] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [9]
[1,0]<stdout>:[2021-12-09 02:24:28,106] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [10]
[1,0]<stdout>:[2021-12-09 02:24:28,117] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [11]
[1,0]<stdout>:[2021-12-09 02:24:28,127] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [12]
[1,0]<stdout>:[2021-12-09 02:24:28,137] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [13]
[1,0]<stdout>:[2021-12-09 02:24:28,148] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [14]
[1,0]<stdout>:[2021-12-09 02:24:28,158] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [15]
[1,0]<stdout>:[2021-12-09 02:24:28,168] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [16]
[1,0]<stdout>:[2021-12-09 02:24:28,179] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [17]
[1,0]<stdout>:[2021-12-09 02:24:28,189] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [18]
[1,0]<stdout>:[2021-12-09 02:24:28,199] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [19]
[1,0]<stdout>:[2021-12-09 02:24:28,210] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [20]
[1,0]<stdout>:[2021-12-09 02:24:28,220] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [21]
[1,0]<stdout>:[2021-12-09 02:24:28,230] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [22]
[1,0]<stdout>:[2021-12-09 02:24:28,240] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [23]
[1,0]<stdout>:[2021-12-09 02:24:28,251] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [24]
[1,0]<stdout>:[2021-12-09 02:24:28,261] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [25]
[1,0]<stdout>:[2021-12-09 02:24:28,271] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [26]
[1,0]<stdout>:[2021-12-09 02:24:28,282] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [27]
[1,0]<stdout>:[2021-12-09 02:24:28,292] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [28]
[1,0]<stdout>:[2021-12-09 02:24:28,302] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [29]
[1,0]<stdout>:[2021-12-09 02:24:28,313] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [30]
[1,0]<stdout>:[2021-12-09 02:24:28,323] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert data parallel process group with ranks: [31]
[1,0]<stdout>:[2021-12-09 02:24:28,333] [INFO] [logging.py:69:log_dist] [Rank 0] creating expert parallel process group with ranks: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]
[1,0]<stdout>:building GPT model ...
[1,0]<stdout>:[2021-12-09 02:24:28,409] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,0]<stdout>:[2021-12-09 02:24:28,469] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,0]<stdout>:[2021-12-09 02:24:28,566] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,0]<stdout>:[2021-12-09 02:24:28,632] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,0]<stdout>:[2021-12-09 02:24:28,696] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,0]<stdout>:[2021-12-09 02:24:28,763] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,0]<stdout>:[2021-12-09 02:24:28,829] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,0]<stdout>:[2021-12-09 02:24:28,893] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,0]<stdout>:[2021-12-09 02:24:28,960] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,0]<stdout>:[2021-12-09 02:24:29,024] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,0]<stdout>:[2021-12-09 02:24:29,091] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,0]<stdout>:[2021-12-09 02:24:29,155] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,0]<stdout>:[2021-12-09 02:24:29,223] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,0]<stdout>:[2021-12-09 02:24:29,290] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,17]<stdout>:[2021-12-09 02:24:29,321] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,24]<stdout>:[2021-12-09 02:24:29,333] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,17]<stdout>:moe = True, moe_experts= 128
[1,17]<stdout>:************ 1 ***********
[1,31]<stdout>:[2021-12-09 02:24:29,337] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,16]<stdout>:[2021-12-09 02:24:29,335] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,24]<stdout>:moe = True, moe_experts= 128
[1,24]<stdout>:************ 1 ***********
[1,30]<stdout>:[2021-12-09 02:24:29,346] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,31]<stdout>:moe = True, moe_experts= 128
[1,31]<stdout>:************ 1 ***********
[1,21]<stdout>:[2021-12-09 02:24:29,345] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,16]<stdout>:moe = True, moe_experts= 128
[1,16]<stdout>:************ 1 ***********
[1,23]<stdout>:[2021-12-09 02:24:29,348] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,18]<stdout>:[2021-12-09 02:24:29,351] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,26]<stdout>:[2021-12-09 02:24:29,355] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,20]<stdout>:[2021-12-09 02:24:29,352] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,19]<stdout>:[2021-12-09 02:24:29,353] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,0]<stdout>:[2021-12-09 02:24:29,357] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,30]<stdout>:moe = True, moe_experts= 128
[1,30]<stdout>:************ 1 ***********
[1,22]<stdout>:[2021-12-09 02:24:29,353] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,29]<stdout>:[2021-12-09 02:24:29,356] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,25]<stdout>:[2021-12-09 02:24:29,358] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,21]<stdout>:moe = True, moe_experts= 128
[1,27]<stdout>:[2021-12-09 02:24:29,359] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,21]<stdout>:************ 1 ***********
[1,28]<stdout>:[2021-12-09 02:24:29,359] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,23]<stdout>:moe = True, moe_experts= 128
[1,23]<stdout>:************ 1 ***********
[1,18]<stdout>:moe = True, moe_experts= 128
[1,18]<stdout>:************ 1 ***********
[1,26]<stdout>:moe = True, moe_experts= 128
[1,26]<stdout>:************ 1 ***********
[1,20]<stdout>:moe = True, moe_experts= 128
[1,20]<stdout>:************ 1 ***********
[1,19]<stdout>:moe = True, moe_experts= 128
[1,19]<stdout>:************ 1 ***********
[1,22]<stdout>:moe = True, moe_experts= 128
[1,22]<stdout>:************ 1 ***********
[1,29]<stdout>:moe = True, moe_experts= 128
[1,29]<stdout>:************ 1 ***********
[1,25]<stdout>:moe = True, moe_experts= 128
[1,25]<stdout>:************ 1 ***********
[1,27]<stdout>:moe = True, moe_experts= 128
[1,27]<stdout>:************ 1 ***********
[1,28]<stdout>:moe = True, moe_experts= 128
[1,28]<stdout>:************ 1 ***********
[1,17]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,17]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,17]<stdout>:Loading extension module transformer_inference...
[1,17]<stdout>:Time to load transformer_inference op: 0.03741955757141113 seconds
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,16]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,16]<stdout>:Loading extension module transformer_inference...
[1,16]<stdout>:Time to load transformer_inference op: 0.03356289863586426 seconds
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,31]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,24]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,24]<stdout>:Loading extension module transformer_inference...
[1,31]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,31]<stdout>:Loading extension module transformer_inference...
[1,24]<stdout>:Time to load transformer_inference op: 0.04356718063354492 seconds
[1,31]<stdout>:Time to load transformer_inference op: 0.04076957702636719 seconds
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,0]<stdout>:[2021-12-09 02:24:29,423] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,30]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,30]<stdout>:Loading extension module transformer_inference...
[1,30]<stdout>:Time to load transformer_inference op: 0.03484916687011719 seconds
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,21]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,21]<stdout>:Loading extension module transformer_inference...
[1,21]<stdout>:Time to load transformer_inference op: 0.03652358055114746 seconds
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,29]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,29]<stdout>:Loading extension module transformer_inference...
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,23]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,29]<stdout>:Time to load transformer_inference op: 0.034212350845336914 seconds
[1,18]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,23]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,23]<stdout>:Loading extension module transformer_inference...
[1,18]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,18]<stdout>:Loading extension module transformer_inference...
[1,23]<stdout>:Time to load transformer_inference op: 0.03763127326965332 seconds
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,26]<stdout>:Loading extension module transformer_inference...
[1,18]<stdout>:Time to load transformer_inference op: 0.03630542755126953 seconds
[1,20]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,20]<stdout>:Loading extension module transformer_inference...
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:Time to load transformer_inference op: 0.0350039005279541 seconds
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:Time to load transformer_inference op: 0.03492474555969238 seconds
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,22]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,28]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,25]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,25]<stdout>:Loading extension module transformer_inference...
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:Time to load transformer_inference op: 0.03467845916748047 seconds
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,22]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,22]<stdout>:Loading extension module transformer_inference...
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,28]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,28]<stdout>:Loading extension module transformer_inference...
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,22]<stdout>:Time to load transformer_inference op: 0.03587484359741211 seconds
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:Time to load transformer_inference op: 0.033422231674194336 seconds
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,27]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,27]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,27]<stdout>:Loading extension module transformer_inference...
[1,27]<stdout>:Time to load transformer_inference op: 0.03556060791015625 seconds
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,19]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,19]<stdout>:Loading extension module transformer_inference...
[1,19]<stdout>:Time to load transformer_inference op: 0.03803396224975586 seconds
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:[2021-12-09 02:24:29,461] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,10]<stdout>:[2021-12-09 02:24:29,469] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,12]<stdout>:moe = True, moe_experts= 128
[1,12]<stdout>:************ 1 ***********
[1,13]<stdout>:[2021-12-09 02:24:29,473] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,8]<stdout>:[2021-12-09 02:24:29,475] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,15]<stdout>:[2021-12-09 02:24:29,478] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,10]<stdout>:moe = True, moe_experts= 128
[1,10]<stdout>:************ 1 ***********
[1,11]<stdout>:[2021-12-09 02:24:29,480] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,14]<stdout>:[2021-12-09 02:24:29,482] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,17]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,16]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,16]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,16]<stdout>:Loading extension module transformer_inference...
[1,17]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,17]<stdout>:Loading extension module transformer_inference...
[1,13]<stdout>:moe = True, moe_experts= 128
[1,13]<stdout>:************ 1 ***********
[1,16]<stdout>:Time to load transformer_inference op: 0.03427553176879883 seconds
[1,17]<stdout>:Time to load transformer_inference op: 0.03749656677246094 seconds
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:local_ep_size = 4
[1,16]<stdout>:local_ep_size = 4
[1,9]<stdout>:[2021-12-09 02:24:29,485] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,8]<stdout>:moe = True, moe_experts= 128
[1,8]<stdout>:************ 1 ***********
[1,15]<stdout>:moe = True, moe_experts= 128
[1,0]<stdout>:[2021-12-09 02:24:29,491] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,15]<stdout>:************ 1 ***********
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:moe = True, moe_experts= 128
[1,11]<stdout>:************ 1 ***********
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:moe = True, moe_experts= 128
[1,14]<stdout>:************ 1 ***********
[1,31]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,31]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,31]<stdout>:Loading extension module transformer_inference...
[1,31]<stdout>:Time to load transformer_inference op: 0.034816741943359375 seconds
[1,24]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,24]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,24]<stdout>:Loading extension module transformer_inference...
[1,31]<stdout>:local_ep_size = 4
[1,17]<stdout>:local_ep_size = 4
[1,24]<stdout>:Time to load transformer_inference op: 0.03553366661071777 seconds
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,16]<stdout>:local_ep_size = 4
[1,24]<stdout>:local_ep_size = 4
[1,9]<stdout>:moe = True, moe_experts= 128
[1,30]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,9]<stdout>:************ 1 ***********
[1,30]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,30]<stdout>:Loading extension module transformer_inference...
[1,30]<stdout>:Time to load transformer_inference op: 0.03597068786621094 seconds
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:local_ep_size = 4
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,16]<stdout>:local_ep_size = 4
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:local_ep_size = 4
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,31]<stdout>:local_ep_size = 4
[1,21]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,29]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,21]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,21]<stdout>:Loading extension module transformer_inference...
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,20]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,29]<stdout>:Loading extension module transformer_inference...
[1,21]<stdout>:Time to load transformer_inference op: 0.03515362739562988 seconds
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,29]<stdout>:Time to load transformer_inference op: 0.03438377380371094 seconds
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,20]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,20]<stdout>:Loading extension module transformer_inference...
[1,21]<stdout>:local_ep_size = 4
[1,20]<stdout>:Time to load transformer_inference op: 0.03316307067871094 seconds
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,24]<stdout>:local_ep_size = 4
[1,29]<stdout>:local_ep_size = 4
[1,20]<stdout>:local_ep_size = 4
[1,26]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:local_ep_size = 4
[1,26]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,26]<stdout>:Loading extension module transformer_inference...
[1,26]<stdout>:Time to load transformer_inference op: 0.03524160385131836 seconds
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,25]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,18]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,26]<stdout>:local_ep_size = 4
[1,23]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,28]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,28]<stdout>:Loading extension module transformer_inference...
[1,25]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,25]<stdout>:Loading extension module transformer_inference...
[1,18]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,18]<stdout>:Loading extension module transformer_inference...
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,28]<stdout>:Time to load transformer_inference op: 0.034331560134887695 seconds
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,25]<stdout>:Time to load transformer_inference op: 0.0354914665222168 seconds
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:Time to load transformer_inference op: 0.03641080856323242 seconds
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,23]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,23]<stdout>:Loading extension module transformer_inference...
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:Time to load transformer_inference op: 0.03673839569091797 seconds
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:local_ep_size = 4
[1,25]<stdout>:local_ep_size = 4
[1,18]<stdout>:local_ep_size = 4
[1,22]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,23]<stdout>:local_ep_size = 4
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,22]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,22]<stdout>:Loading extension module transformer_inference...
[1,22]<stdout>:Time to load transformer_inference op: 0.03591442108154297 seconds
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,16]<stdout>:local_ep_size = 4
[1,27]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,22]<stdout>:local_ep_size = 4
[1,17]<stdout>:local_ep_size = 4
[1,31]<stdout>:local_ep_size = 4
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,27]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,27]<stdout>:Loading extension module transformer_inference...
[1,27]<stdout>:Time to load transformer_inference op: 0.034828901290893555 seconds
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,27]<stdout>:local_ep_size = 4
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:local_ep_size = 4
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:local_ep_size = 4
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,24]<stdout>:local_ep_size = 4
[1,19]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,19]<stdout>:Loading extension module transformer_inference...
[1,20]<stdout>:local_ep_size = 4
[1,19]<stdout>:Time to load transformer_inference op: 0.036803245544433594 seconds
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,19]<stdout>:local_ep_size = 4
[1,30]<stdout>:local_ep_size = 4
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:local_ep_size = 4
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,18]<stdout>:local_ep_size = 4
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:local_ep_size = 4
[1,16]<stdout>:local_ep_size = 4
[1,17]<stdout>:local_ep_size = 4
[1,25]<stdout>:local_ep_size = 4
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,31]<stdout>:local_ep_size = 4
[1,23]<stdout>:local_ep_size = 4
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:local_ep_size = 4
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:local_ep_size = 4
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,21]<stdout>:local_ep_size = 4
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:local_ep_size = 4
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,20]<stdout>:local_ep_size = 4
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:local_ep_size = 4
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,19]<stdout>:local_ep_size = 4
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:local_ep_size = 4
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:local_ep_size = 4
[1,16]<stdout>:local_ep_size = 4
[1,17]<stdout>:local_ep_size = 4
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:local_ep_size = 4
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:local_ep_size = 4
[1,25]<stdout>:local_ep_size = 4
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:local_ep_size = 4
[1,27]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:local_ep_size = 4
[1,21]<stdout>:local_ep_size = 4
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:local_ep_size = 4
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,20]<stdout>:local_ep_size = 4
[1,18]<stdout>:local_ep_size = 4
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:local_ep_size = 4
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,16]<stdout>:local_ep_size = 4
[1,19]<stdout>:local_ep_size = 4
[1,17]<stdout>:local_ep_size = 4
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:local_ep_size = 4
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:local_ep_size = 4
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,12]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,12]<stdout>:Loading extension module transformer_inference...
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:Time to load transformer_inference op: 0.03968381881713867 seconds
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:local_ep_size = 4
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:local_ep_size = 4
[1,25]<stdout>:local_ep_size = 4
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:local_ep_size = 4
[1,23]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,10]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,22]<stdout>:local_ep_size = 4
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,10]<stdout>:Loading extension module transformer_inference...
[1,29]<stdout>:local_ep_size = 4
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,10]<stdout>:Time to load transformer_inference op: 0.03640604019165039 seconds
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:local_ep_size = 4
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:local_ep_size = 4
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:local_ep_size = 4
[1,16]<stdout>:local_ep_size = 4
[1,30]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,19]<stdout>:local_ep_size = 4
[1,31]<stdout>:local_ep_size = 4
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,27]<stdout>:local_ep_size = 4
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:local_ep_size = 4
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,28]<stdout>:local_ep_size = 4
[1,25]<stdout>:local_ep_size = 4
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:local_ep_size = 4
[1,13]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,23]<stdout>:local_ep_size = 4
[1,8]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,8]<stdout>:Loading extension module transformer_inference...
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:Time to load transformer_inference op: 0.03701424598693848 seconds
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,13]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,13]<stdout>:Loading extension module transformer_inference...
[1,22]<stdout>:local_ep_size = 4
[1,0]<stdout>:[2021-12-09 02:24:29,562] [INFO] [logging.py:69:log_dist] [Rank 0] num_experts: 128 | num_local_experts: 4 | expert_parallel_size: 32
[1,13]<stdout>:Time to load transformer_inference op: 0.03866767883300781 seconds
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,11]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4
[1,11]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,11]<stdout>:Loading extension module transformer_inference...
[1,14]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,11]<stdout>:Time to load transformer_inference op: 0.03543353080749512 seconds
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,14]<stdout>:Loading extension module transformer_inference...
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:Time to load transformer_inference op: 0.034552812576293945 seconds
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:local_ep_size = 4
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:local_ep_size = 4
[1,15]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,24]<stdout>:local_ep_size = 4
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:local_ep_size = 4
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:local_ep_size = 4
[1,15]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,15]<stdout>:Loading extension module transformer_inference...
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,15]<stdout>:Time to load transformer_inference op: 0.03880572319030762 seconds
[1,30]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:local_ep_size = 4
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,19]<stdout>:local_ep_size = 4
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,31]<stdout>:local_ep_size = 4
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:local_ep_size = 4
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,9]<stdout>:Loading extension module transformer_inference...
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,25]<stdout>:local_ep_size = 4
[1,9]<stdout>:Time to load transformer_inference op: 0.03758502006530762 seconds
[1,28]<stdout>:local_ep_size = 4
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,21]<stdout>:local_ep_size = 4
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,22]<stdout>:local_ep_size = 4
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:local_ep_size = 4
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:local_ep_size = 4
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,27]<stdout>:local_ep_size = 4
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,20]<stdout>:local_ep_size = 4
[1,24]<stdout>:local_ep_size = 4
[1,16]<stdout>:local_ep_size = 4
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:local_ep_size = 4
[1,19]<stdout>:local_ep_size = 4
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:local_ep_size = 4
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:local_ep_size = 4
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:local_ep_size = 4
[1,23]<stdout>:local_ep_size = 4
[1,28]<stdout>:local_ep_size = 4
[1,21]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:local_ep_size = 4
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4
[1,18]<stdout>:local_ep_size = 4
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:local_ep_size = 4
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,27]<stdout>:local_ep_size = 4
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,20]<stdout>:local_ep_size = 4
[1,16]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:local_ep_size = 4
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,19]<stdout>:local_ep_size = 4
[1,30]<stdout>:local_ep_size = 4
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:local_ep_size = 4
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:local_ep_size = 4
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,23]<stdout>:local_ep_size = 4
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:local_ep_size = 4
[1,21]<stdout>:local_ep_size = 4
[1,28]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:local_ep_size = 4
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,29]<stdout>:local_ep_size = 4
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:local_ep_size = 4
[1,27]<stdout>:local_ep_size = 4
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,17]<stdout>:local_ep_size = 4
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,20]<stdout>:local_ep_size = 4
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,16]<stdout>:local_ep_size = 4
[1,24]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:local_ep_size = 4
[1,19]<stdout>:local_ep_size = 4
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,31]<stdout>:local_ep_size = 4
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:local_ep_size = 4
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:local_ep_size = 4
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:local_ep_size = 4
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:local_ep_size = 4
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,22]<stdout>:local_ep_size = 4
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,0]<stdout>: > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 8320757760
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,0]<stdout>:[2021-12-09 02:24:29,608] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed info: version=0.5.7+e806499e, git-hash=e806499e, git-branch=merge-moe-specialized
[1,0]<stdout>:[2021-12-09 02:24:29,608] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:local_ep_size = 4
[1,27]<stdout>:local_ep_size = 4
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:local_ep_size = 4
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:local_ep_size = 4
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,24]<stdout>:local_ep_size = 4
[1,19]<stdout>:local_ep_size = 4
[1,30]<stdout>:local_ep_size = 4
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,31]<stdout>:local_ep_size = 4
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,26]<stdout>:local_ep_size = 4
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:[2021-12-09 02:24:29,616] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:moe = True, moe_experts= 128
[1,0]<stdout>:************ 1 ***********
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:local_ep_size = 4
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,25]<stdout>:local_ep_size = 4
[1,28]<stdout>:local_ep_size = 4
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,22]<stdout>:local_ep_size = 4
[1,4]<stdout>:[2021-12-09 02:24:29,619] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:local_ep_size = 4
[1,27]<stdout>:local_ep_size = 4
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,17]<stdout>:local_ep_size = 4
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:[2021-12-09 02:24:29,623] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,20]<stdout>:local_ep_size = 4
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,16]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,12]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,12]<stdout>:Loading extension module transformer_inference...
[1,19]<stdout>:local_ep_size = 4
[1,24]<stdout>:local_ep_size = 4
[1,12]<stdout>:Time to load transformer_inference op: 0.03723287582397461 seconds
[1,30]<stdout>:local_ep_size = 4
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:[2021-12-09 02:24:29,626] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,6]<stdout>:moe = True, moe_experts= 128
[1,6]<stdout>:************ 1 ***********
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,10]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,12]<stdout>:local_ep_size = 4
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,31]<stdout>:local_ep_size = 4
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,10]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,10]<stdout>:Loading extension module transformer_inference...
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,26]<stdout>:local_ep_size = 4
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:Time to load transformer_inference op: 0.03673720359802246 seconds
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,10]<stdout>:local_ep_size = 4
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,1]<stdout>:[2021-12-09 02:24:29,629] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,5]<stdout>:[2021-12-09 02:24:29,629] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,4]<stdout>:moe = True, moe_experts= 128
[1,4]<stdout>:************ 1 ***********
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:local_ep_size = 4
[1,3]<stdout>:[2021-12-09 02:24:29,630] [INFO] [engine.py:151:_init_quantization_setting] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:local_ep_size = 4
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:local_ep_size = 4
[1,22]<stdout>:local_ep_size = 4
[1,28]<stdout>:local_ep_size = 4
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:local_ep_size = 4
[1,27]<stdout>:local_ep_size = 4
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,17]<stdout>:local_ep_size = 4
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:moe = True, moe_experts= 128
[1,2]<stdout>:************ 1 ***********
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:moe = True, moe_experts= 128
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:************ 1 ***********
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,20]<stdout>:local_ep_size = 4
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:local_ep_size = 4
[1,24]<stdout>:local_ep_size = 4
[1,16]<stdout>:local_ep_size = 4
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,19]<stdout>:local_ep_size = 4
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,14]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,11]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,11]<stdout>:Loading extension module transformer_inference...
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:Time to load transformer_inference op: 0.03524971008300781 seconds
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,14]<stdout>:Loading extension module transformer_inference...
[1,12]<stdout>:local_ep_size = 4
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,14]<stdout>:Time to load transformer_inference op: 0.03464651107788086 seconds
[1,31]<stdout>:local_ep_size = 4
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,8]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,11]<stdout>:local_ep_size = 4
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,26]<stdout>:local_ep_size = 4
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,14]<stdout>:local_ep_size = 4
[1,1]<stdout>:moe = True, moe_experts= 128
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:************ 1 ***********
[1,8]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,8]<stdout>:Loading extension module transformer_inference...
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:Time to load transformer_inference op: 0.03641819953918457 seconds
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:moe = True, moe_experts= 128
[1,5]<stdout>:************ 1 ***********
[1,10]<stdout>:local_ep_size = 4
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,3]<stdout>:moe = True, moe_experts= 128
[1,3]<stdout>:************ 1 ***********
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:local_ep_size = 4
[1,13]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,13]<stdout>:Loading extension module transformer_inference...
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:local_ep_size = 4
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:Time to load transformer_inference op: 0.03745245933532715 seconds
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,21]<stdout>:local_ep_size = 4
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:local_ep_size = 4
[1,28]<stdout>:local_ep_size = 4
[1,22]<stdout>:local_ep_size = 4
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,13]<stdout>:local_ep_size = 4
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:local_ep_size = 4
[1,18]<stdout>:local_ep_size = 4
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:local_ep_size = 4
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,15]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,15]<stdout>:Loading extension module transformer_inference...
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:Time to load transformer_inference op: 0.03760933876037598 seconds
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:local_ep_size = 4
[1,20]<stdout>:local_ep_size = 4
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:local_ep_size = 4
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,16]<stdout>:local_ep_size = 4
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,19]<stdout>:local_ep_size = 4
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,12]<stdout>:local_ep_size = 4
[1,9]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:local_ep_size = 4
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:local_ep_size = 4
[1,9]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,9]<stdout>:Loading extension module transformer_inference...
[1,26]<stdout>:local_ep_size = 4
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:local_ep_size = 4
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,9]<stdout>:Time to load transformer_inference op: 0.03703570365905762 seconds
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:local_ep_size = 4
[1,9]<stdout>:local_ep_size = 4
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:local_ep_size = 4
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,23]<stdout>:local_ep_size = 4
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:local_ep_size = 4
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:local_ep_size = 4
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:local_ep_size = 4
[1,13]<stdout>:local_ep_size = 4
[1,28]<stdout>:local_ep_size = 4
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:local_ep_size = 4
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:local_ep_size = 4
[1,17]<stdout>:local_ep_size = 4
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:local_ep_size = 4
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,20]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:local_ep_size = 4
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,16]<stdout>:local_ep_size = 4
[1,19]<stdout>:local_ep_size = 4
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:local_ep_size = 4
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:local_ep_size = 4
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,31]<stdout>:local_ep_size = 4
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:local_ep_size = 4
[1,26]<stdout>:local_ep_size = 4
[1,14]<stdout>:local_ep_size = 4
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,17]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:local_ep_size = 4
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:local_ep_size = 4
[1,8]<stdout>:local_ep_size = 4
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,23]<stdout>:local_ep_size = 4
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:moe, num_experts = True, 4, MoE(
[1,17]<stdout>:  (deepspeed_moe): MOELayer(
[1,17]<stdout>:    (gate): TopKGate(
[1,17]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,17]<stdout>:    )
[1,17]<stdout>:    (experts): Experts(
[1,17]<stdout>:      (deepspeed_experts): ModuleList(
[1,17]<stdout>:        (0): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (1): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (2): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:        (3): ParallelMLP(
[1,17]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,17]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,17]<stdout>:        )
[1,17]<stdout>:      )
[1,17]<stdout>:    )
[1,17]<stdout>:  )
[1,17]<stdout>:), 4
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:local_ep_size = 4
[1,25]<stdout>:local_ep_size = 4
[1,22]<stdout>:local_ep_size = 4
[1,13]<stdout>:local_ep_size = 4
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,16]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:local_ep_size = 4
[1,17]<stdout>:local_ep_size = 4
[1,18]<stdout>:local_ep_size = 4
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:moe, num_experts = True, 4, MoE(
[1,16]<stdout>:  (deepspeed_moe): MOELayer(
[1,16]<stdout>:    (gate): TopKGate(
[1,16]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,16]<stdout>:    )
[1,16]<stdout>:    (experts): Experts(
[1,16]<stdout>:      (deepspeed_experts): ModuleList(
[1,16]<stdout>:        (0): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (1): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (2): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:        (3): ParallelMLP(
[1,16]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,16]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,16]<stdout>:        )
[1,16]<stdout>:      )
[1,16]<stdout>:    )
[1,16]<stdout>:  )
[1,16]<stdout>:), 4
[1,16]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:local_ep_size = 4
[1,16]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:local_ep_size = 4
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:local_ep_size = 4
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,19]<stdout>:local_ep_size = 4
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,30]<stdout>:local_ep_size = 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:local_ep_size = 4
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,24]<stdout>:local_ep_size = 4
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:local_ep_size = 4
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:local_ep_size = 4
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:local_ep_size = 4
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,26]<stdout>:local_ep_size = 4
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,10]<stdout>:local_ep_size = 4
[1,9]<stdout>:local_ep_size = 4
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,17]<stdout>:[2021-12-09 02:24:29,671] [INFO] [engine.py:107:__init__] Place model to device: 1
[1,8]<stdout>:local_ep_size = 4
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,28]<stdout>:local_ep_size = 4
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,23]<stdout>:local_ep_size = 4
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:local_ep_size = 4
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:local_ep_size = 4
[1,13]<stdout>:local_ep_size = 4
[1,25]<stdout>:local_ep_size = 4
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:local_ep_size = 4
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,16]<stdout>:[2021-12-09 02:24:29,675] [INFO] [engine.py:107:__init__] Place model to device: 0
[1,31]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:local_ep_size = 4
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:moe, num_experts = True, 4, MoE(
[1,31]<stdout>:  (deepspeed_moe): MOELayer(
[1,31]<stdout>:    (gate): TopKGate(
[1,31]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,31]<stdout>:    )
[1,31]<stdout>:    (experts): Experts(
[1,31]<stdout>:      (deepspeed_experts): ModuleList(
[1,31]<stdout>:        (0): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (1): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (2): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:        (3): ParallelMLP(
[1,31]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,31]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,31]<stdout>:        )
[1,31]<stdout>:      )
[1,31]<stdout>:    )
[1,31]<stdout>:  )
[1,31]<stdout>:), 4
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,31]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:local_ep_size = 4
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,20]<stdout>:local_ep_size = 4
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,19]<stdout>:local_ep_size = 4
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:local_ep_size = 4
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:local_ep_size = 4
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:local_ep_size = 4
[1,24]<stdout>:local_ep_size = 4
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,31]<stdout>:local_ep_size = 4
[1,14]<stdout>:local_ep_size = 4
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,26]<stdout>:local_ep_size = 4
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,28]<stdout>:local_ep_size = 4
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:local_ep_size = 4
[1,9]<stdout>:local_ep_size = 4
[1,8]<stdout>:local_ep_size = 4
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,25]<stdout>:local_ep_size = 4
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,13]<stdout>:local_ep_size = 4
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:> DeepSpeed Inference initialized
[1,23]<stdout>:local_ep_size = 4
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,21]<stdout>:local_ep_size = 4
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,22]<stdout>:local_ep_size = 4
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,30]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,29]<stdout>:local_ep_size = 4
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,0]<stdout>:Loading extension module transformer_inference...
[1,27]<stdout>:local_ep_size = 4
[1,30]<stdout>:moe, num_experts = True, 4, MoE(
[1,30]<stdout>:  (deepspeed_moe): MOELayer(
[1,30]<stdout>:    (gate): TopKGate(
[1,30]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,30]<stdout>:    )
[1,30]<stdout>:    (experts): Experts(
[1,30]<stdout>:      (deepspeed_experts): ModuleList(
[1,30]<stdout>:        (0): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (1): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (2): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:        (3): ParallelMLP(
[1,30]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,30]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,30]<stdout>:        )
[1,30]<stdout>:      )
[1,30]<stdout>:    )
[1,30]<stdout>:  )
[1,30]<stdout>:), 4
[1,30]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:moe, num_experts = True, 4, MoE(
[1,24]<stdout>:  (deepspeed_moe): MOELayer(
[1,24]<stdout>:    (gate): TopKGate(
[1,24]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,24]<stdout>:    )
[1,24]<stdout>:    (experts): Experts(
[1,24]<stdout>:      (deepspeed_experts): ModuleList(
[1,24]<stdout>:        (0): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (1): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (2): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:        (3): ParallelMLP(
[1,24]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,24]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,24]<stdout>:        )
[1,24]<stdout>:      )
[1,24]<stdout>:    )
[1,24]<stdout>:  )
[1,24]<stdout>:), 4
[1,18]<stdout>:local_ep_size = 4
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:> DeepSpeed Inference initialized
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:[2021-12-09 02:24:29,691] [INFO] [engine.py:107:__init__] Place model to device: 7
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,0]<stdout>:Time to load transformer_inference op: 0.04112553596496582 seconds
[1,0]<stdout>:DeepSpeed Transformer Inference config is  [1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,0]<stdout>:{'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,30]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,15]<stdout>:local_ep_size = 4
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:local_ep_size = 4
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,21]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,24]<stdout>:local_ep_size = 4
[1,20]<stdout>:local_ep_size = 4
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:local_ep_size = 4
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:local_ep_size = 4
[1,29]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:local_ep_size = 4
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,14]<stdout>:local_ep_size = 4
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,28]<stdout>:local_ep_size = 4
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,27]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,21]<stdout>:moe, num_experts = True, 4, MoE(
[1,21]<stdout>:  (deepspeed_moe): MOELayer(
[1,21]<stdout>:    (gate): TopKGate(
[1,21]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,21]<stdout>:    )
[1,21]<stdout>:    (experts): Experts(
[1,21]<stdout>:      (deepspeed_experts): ModuleList(
[1,21]<stdout>:        (0): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (1): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (2): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:        (3): ParallelMLP(
[1,21]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,21]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,21]<stdout>:        )
[1,21]<stdout>:      )
[1,21]<stdout>:    )
[1,21]<stdout>:  )
[1,21]<stdout>:), 4
[1,21]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,26]<stdout>:local_ep_size = 4
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,25]<stdout>:local_ep_size = 4
[1,9]<stdout>:local_ep_size = 4
[1,29]<stdout>:moe, num_experts = True, 4, MoE(
[1,29]<stdout>:  (deepspeed_moe): MOELayer(
[1,29]<stdout>:    (gate): TopKGate(
[1,29]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,29]<stdout>:    )
[1,29]<stdout>:    (experts): Experts(
[1,29]<stdout>:      (deepspeed_experts): ModuleList(
[1,29]<stdout>:        (0): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (1): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (2): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:        (3): ParallelMLP(
[1,29]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,29]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,29]<stdout>:        )
[1,29]<stdout>:      )
[1,29]<stdout>:    )
[1,29]<stdout>:  )
[1,29]<stdout>:), 4
[1,10]<stdout>:local_ep_size = 4
[1,8]<stdout>:local_ep_size = 4
[1,29]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:moe, num_experts = True, 4, MoE(
[1,27]<stdout>:  (deepspeed_moe): MOELayer(
[1,27]<stdout>:    (gate): TopKGate(
[1,27]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,27]<stdout>:    )
[1,27]<stdout>:    (experts): Experts(
[1,27]<stdout>:      (deepspeed_experts): ModuleList(
[1,27]<stdout>:        (0): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (1): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (2): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:        (3): ParallelMLP(
[1,27]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,27]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,27]<stdout>:        )
[1,27]<stdout>:      )
[1,27]<stdout>:    )
[1,27]<stdout>:  )
[1,27]<stdout>:), 4
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,17]<stdout>:NCCL version 2.8.4+cuda11.3
[1,27]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,16]<stdout>:NCCL version 2.8.4+cuda11.3
[1,23]<stdout>:local_ep_size = 4
[1,13]<stdout>:local_ep_size = 4
[1,21]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:moe, num_experts = True, 4, MoE(
[1,18]<stdout>:  (deepspeed_moe): MOELayer(
[1,18]<stdout>:    (gate): TopKGate(
[1,18]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,18]<stdout>:    )
[1,18]<stdout>:    (experts): Experts(
[1,18]<stdout>:      (deepspeed_experts): ModuleList(
[1,18]<stdout>:        (0): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (1): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (2): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:        (3): ParallelMLP(
[1,18]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,18]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,18]<stdout>:        )
[1,18]<stdout>:      )
[1,18]<stdout>:    )
[1,18]<stdout>:  )
[1,18]<stdout>:), 4
[1,21]<stdout>:local_ep_size = 4
[1,18]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,6]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:[2021-12-09 02:24:29,699] [INFO] [engine.py:107:__init__] Place model to device: 6
[1,29]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,29]<stdout>:local_ep_size = 4
[1,4]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,4]<stdout>:Loading extension module transformer_inference...
[1,6]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,6]<stdout>:Loading extension module transformer_inference...
[1,22]<stdout>:local_ep_size = 4
[1,20]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,24]<stdout>:[2021-12-09 02:24:29,700] [INFO] [engine.py:107:__init__] Place model to device: 0
[1,4]<stdout>:Time to load transformer_inference op: 0.036015987396240234 seconds
[1,4]<stdout>:DeepSpeed Transformer Inference config is  [1,4]<stdout>:{'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,6]<stdout>:Time to load transformer_inference op: 0.038538455963134766 seconds
[1,6]<stdout>:DeepSpeed Transformer Inference config is  [1,6]<stdout>:{'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,28]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,27]<stdout>:local_ep_size = 4
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,18]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,18]<stdout>:local_ep_size = 4
[1,20]<stdout>:moe, num_experts = True, 4, MoE(
[1,20]<stdout>:  (deepspeed_moe): MOELayer(
[1,20]<stdout>:    (gate): TopKGate(
[1,20]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,20]<stdout>:    )
[1,20]<stdout>:    (experts): Experts(
[1,20]<stdout>:      (deepspeed_experts): ModuleList(
[1,20]<stdout>:        (0): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (1): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (2): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:        (3): ParallelMLP(
[1,20]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,20]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,20]<stdout>:        )
[1,20]<stdout>:      )
[1,20]<stdout>:    )
[1,20]<stdout>:  )
[1,20]<stdout>:), 4
[1,20]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,26]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,28]<stdout>:moe, num_experts = True, 4, MoE(
[1,28]<stdout>:  (deepspeed_moe): MOELayer(
[1,28]<stdout>:    (gate): TopKGate(
[1,28]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,28]<stdout>:    )
[1,28]<stdout>:    (experts): Experts(
[1,28]<stdout>:      (deepspeed_experts): ModuleList(
[1,28]<stdout>:        (0): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (1): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (2): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:        (3): ParallelMLP(
[1,28]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,28]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,28]<stdout>:        )
[1,28]<stdout>:      )
[1,28]<stdout>:    )
[1,28]<stdout>:  )
[1,28]<stdout>:), 4
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,28]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,23]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:moe, num_experts = True, 4, MoE(
[1,25]<stdout>:  (deepspeed_moe): MOELayer(
[1,25]<stdout>:    (gate): TopKGate(
[1,25]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,25]<stdout>:    )
[1,25]<stdout>:    (experts): Experts(
[1,25]<stdout>:      (deepspeed_experts): ModuleList(
[1,25]<stdout>:        (0): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (1): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (2): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:        (3): ParallelMLP(
[1,25]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,25]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,25]<stdout>:        )
[1,25]<stdout>:      )
[1,25]<stdout>:    )
[1,25]<stdout>:  )
[1,25]<stdout>:), 4
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,25]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,31]<stdout>:> DeepSpeed Inference initialized
[1,15]<stdout>:local_ep_size = 4
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,26]<stdout>:moe, num_experts = True, 4, MoE(
[1,26]<stdout>:  (deepspeed_moe): MOELayer(
[1,26]<stdout>:    (gate): TopKGate(
[1,26]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,26]<stdout>:    )
[1,26]<stdout>:    (experts): Experts(
[1,26]<stdout>:      (deepspeed_experts): ModuleList(
[1,26]<stdout>:        (0): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (1): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (2): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:        (3): ParallelMLP(
[1,26]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,26]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,26]<stdout>:        )
[1,26]<stdout>:      )
[1,26]<stdout>:    )
[1,26]<stdout>:  )
[1,26]<stdout>:), 4
[1,26]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,20]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,23]<stdout>:moe, num_experts = True, 4, MoE(
[1,23]<stdout>:  (deepspeed_moe): MOELayer(
[1,23]<stdout>:    (gate): TopKGate(
[1,23]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,23]<stdout>:    )
[1,23]<stdout>:    (experts): Experts(
[1,23]<stdout>:      (deepspeed_experts): ModuleList(
[1,23]<stdout>:        (0): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (1): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (2): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:        (3): ParallelMLP(
[1,23]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,23]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,23]<stdout>:        )
[1,23]<stdout>:      )
[1,23]<stdout>:    )
[1,23]<stdout>:  )
[1,23]<stdout>:), 4
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,23]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,20]<stdout>:local_ep_size = 4
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,28]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,22]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,28]<stdout>:local_ep_size = 4
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,19]<stdout>:local_ep_size = 4
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,12]<stdout>:local_ep_size = 4
[1,21]<stdout>:[2021-12-09 02:24:29,703] [INFO] [engine.py:107:__init__] Place model to device: 5
[1,2]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,2]<stdout>:Loading extension module transformer_inference...
[1,31]<stdout>:NCCL version 2.8.4+cuda11.3
[1,25]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:local_ep_size = 4
[1,2]<stdout>:Time to load transformer_inference op: 0.036797285079956055 seconds
[1,2]<stdout>:DeepSpeed Transformer Inference config is  [1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:{'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:local_ep_size = 4
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,14]<stdout>:local_ep_size = 4
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:[2021-12-09 02:24:29,707] [INFO] [engine.py:107:__init__] Place model to device: 5
[1,26]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,26]<stdout>:local_ep_size = 4
[1,22]<stdout>:moe, num_experts = True, 4, MoE(
[1,22]<stdout>:  (deepspeed_moe): MOELayer(
[1,22]<stdout>:    (gate): TopKGate(
[1,22]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,22]<stdout>:    )
[1,22]<stdout>:    (experts): Experts(
[1,22]<stdout>:      (deepspeed_experts): ModuleList(
[1,22]<stdout>:        (0): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (1): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (2): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:        (3): ParallelMLP(
[1,22]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,22]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,22]<stdout>:        )
[1,22]<stdout>:      )
[1,22]<stdout>:    )
[1,22]<stdout>:  )
[1,22]<stdout>:), 4
[1,23]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:local_ep_size = 4
[1,23]<stdout>:local_ep_size = 4
[1,8]<stdout>:local_ep_size = 4
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,27]<stdout>:[2021-12-09 02:24:29,708] [INFO] [engine.py:107:__init__] Place model to device: 3
[1,10]<stdout>:local_ep_size = 4
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:[2021-12-09 02:24:29,706] [INFO] [engine.py:107:__init__] Place model to device: 2
[1,13]<stdout>:local_ep_size = 4
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,22]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,22]<stdout>:local_ep_size = 4
[1,19]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,30]<stdout>:> DeepSpeed Inference initialized
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,28]<stdout>:[2021-12-09 02:24:29,712] [INFO] [engine.py:107:__init__] Place model to device: 4
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:[2021-12-09 02:24:29,710] [INFO] [engine.py:107:__init__] Place model to device: 4
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,24]<stdout>:> DeepSpeed Inference initialized
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:[2021-12-09 02:24:29,713] [INFO] [engine.py:107:__init__] Place model to device: 1
[1,1]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,5]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,19]<stdout>:moe, num_experts = True, 4, MoE(
[1,19]<stdout>:  (deepspeed_moe): MOELayer(
[1,19]<stdout>:    (gate): TopKGate(
[1,19]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,19]<stdout>:    )
[1,19]<stdout>:    (experts): Experts(
[1,19]<stdout>:      (deepspeed_experts): ModuleList(
[1,19]<stdout>:        (0): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (1): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (2): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:        (3): ParallelMLP(
[1,19]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,19]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,19]<stdout>:        )
[1,19]<stdout>:      )
[1,19]<stdout>:    )
[1,19]<stdout>:  )
[1,19]<stdout>:), 4
[1,30]<stdout>:NCCL version 2.8.4+cuda11.3
[1,26]<stdout>:[2021-12-09 02:24:29,714] [INFO] [engine.py:107:__init__] Place model to device: 2
[1,1]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,1]<stdout>:Loading extension module transformer_inference...
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,5]<stdout>:Loading extension module transformer_inference...
[1,19]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,23]<stdout>:[2021-12-09 02:24:29,711] [INFO] [engine.py:107:__init__] Place model to device: 7
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,1]<stdout>:Time to load transformer_inference op: 0.03876066207885742 seconds
[1,1]<stdout>:DeepSpeed Transformer Inference config is  [1,1]<stdout>:{'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,5]<stdout>:Time to load transformer_inference op: 0.03845667839050293 seconds
[1,5]<stdout>:DeepSpeed Transformer Inference config is  [1,5]<stdout>:{'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,24]<stdout>:NCCL version 2.8.4+cuda11.3
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:local_ep_size = 4
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,19]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,19]<stdout>:local_ep_size = 4
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:local_ep_size = 4
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,7]<stdout>:Loading extension module transformer_inference...
[1,3]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,3]<stdout>:Loading extension module transformer_inference...
[1,7]<stdout>:Time to load transformer_inference op: 0.04132413864135742 seconds
[1,7]<stdout>:DeepSpeed Transformer Inference config is  [1,7]<stdout>:{'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,3]<stdout>:Time to load transformer_inference op: 0.039373159408569336 seconds
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 0, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:local_ep_size = 4
[1,22]<stdout>:[2021-12-09 02:24:29,715] [INFO] [engine.py:107:__init__] Place model to device: 6
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:local_ep_size = 4
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:local_ep_size = 4
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:local_ep_size = 4
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:local_ep_size = 4
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:local_ep_size = 4
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,21]<stdout>:> DeepSpeed Inference initialized
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:[2021-12-09 02:24:29,722] [INFO] [engine.py:107:__init__] Place model to device: 3
[1,21]<stdout>:NCCL version 2.8.4+cuda11.3
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,29]<stdout>:> DeepSpeed Inference initialized
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:local_ep_size = 4
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,29]<stdout>:NCCL version 2.8.4+cuda11.3
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:local_ep_size = 4
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:local_ep_size = 4
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:local_ep_size = 4
[1,18]<stdout>:> DeepSpeed Inference initialized
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:local_ep_size = 4
[1,8]<stdout>:local_ep_size = 4
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:local_ep_size = 4
[1,27]<stdout>:> DeepSpeed Inference initialized
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,18]<stdout>:NCCL version 2.8.4+cuda11.3
[1,13]<stdout>:local_ep_size = 4
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:> DeepSpeed Inference initialized
[1,27]<stdout>:NCCL version 2.8.4+cuda11.3
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:> DeepSpeed Inference initialized
[1,28]<stdout>:> DeepSpeed Inference initialized
[1,26]<stdout>:> DeepSpeed Inference initialized
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,20]<stdout>:NCCL version 2.8.4+cuda11.3
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,23]<stdout>:> DeepSpeed Inference initialized
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,25]<stdout>:NCCL version 2.8.4+cuda11.3
[1,28]<stdout>:NCCL version 2.8.4+cuda11.3
[1,26]<stdout>:NCCL version 2.8.4+cuda11.3
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,22]<stdout>:> DeepSpeed Inference initialized
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:local_ep_size = 4
[1,23]<stdout>:NCCL version 2.8.4+cuda11.3
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,22]<stdout>:NCCL version 2.8.4+cuda11.3
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:local_ep_size = 4
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:local_ep_size = 4
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:local_ep_size = 4
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:local_ep_size = 4
[1,8]<stdout>:local_ep_size = 4
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:local_ep_size = 4
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:local_ep_size = 4
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:local_ep_size = 4
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,19]<stdout>:> DeepSpeed Inference initialized
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:local_ep_size = 4
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,19]<stdout>:NCCL version 2.8.4+cuda11.3
[1,11]<stdout>:local_ep_size = 4
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:local_ep_size = 4
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:local_ep_size = 4
[1,8]<stdout>:local_ep_size = 4
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:local_ep_size = 4
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:local_ep_size = 4
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:local_ep_size = 4
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,12]<stdout>:local_ep_size = 4
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:local_ep_size = 4
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4
[1,0]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:local_ep_size = 4
[1,0]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,0]<stdout>:Loading extension module transformer_inference...
[1,8]<stdout>:local_ep_size = 4
[1,0]<stdout>:Time to load transformer_inference op: 0.03605294227600098 seconds
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,0]<stdout>:{'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:local_ep_size = 4
[1,10]<stdout>:local_ep_size = 4
[1,13]<stdout>:local_ep_size = 4
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:local_ep_size = 4
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,12]<stdout>:local_ep_size = 4
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,4]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,11]<stdout>:local_ep_size = 4
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4
[1,4]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,4]<stdout>:Loading extension module transformer_inference...
[1,4]<stdout>:Time to load transformer_inference op: 0.03520512580871582 seconds
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,4]<stdout>:{'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:local_ep_size = 4
[1,8]<stdout>:local_ep_size = 4
[1,4]<stdout>:local_ep_size = 4
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,0]<stdout>:{'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:local_ep_size = 4
[1,10]<stdout>:local_ep_size = 4
[1,13]<stdout>:local_ep_size = 4
[1,6]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,6]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,6]<stdout>:Loading extension module transformer_inference...
[1,6]<stdout>:Time to load transformer_inference op: 0.037933349609375 seconds
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:local_ep_size = 4
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,2]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,4]<stdout>:DeepSpeed Transformer Inference config is  [1,4]<stdout>:{'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,2]<stdout>:Loading extension module transformer_inference...
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,0]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:Time to load transformer_inference op: 0.03679776191711426 seconds
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,2]<stdout>:{'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:local_ep_size = 4
[1,2]<stdout>:local_ep_size = 4
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,12]<stdout>:local_ep_size = 4
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:local_ep_size = 4
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,4]<stdout>:{'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:local_ep_size = 4
[1,4]<stdout>:local_ep_size = 4
[1,8]<stdout>:local_ep_size = 4
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,0]<stdout>:{'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:local_ep_size = 4
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:local_ep_size = 4
[1,10]<stdout>:local_ep_size = 4
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,2]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,2]<stdout>:
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:local_ep_size = 4
[1,5]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,5]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,5]<stdout>:Loading extension module transformer_inference...
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:Time to load transformer_inference op: 0.037291765213012695 seconds
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,1]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,1]<stdout>:Loading extension module transformer_inference...
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:Time to load transformer_inference op: 0.037929534912109375 seconds
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:{'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:local_ep_size = 4
[1,1]<stdout>:local_ep_size = 4
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,2]<stdout>:{'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:local_ep_size = 4
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,2]<stdout>:local_ep_size = 4
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,6]<stdout>:
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:local_ep_size = 4
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:local_ep_size = 4
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:local_ep_size = 4
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,0]<stdout>:{'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:DeepSpeed Transformer Inference config is  [1,5]<stdout>:{'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,9]<stdout>:local_ep_size = 4
[1,8]<stdout>:local_ep_size = 4
[1,0]<stdout>:local_ep_size = 4
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,1]<stdout>:DeepSpeed Transformer Inference config is  [1,1]<stdout>:{'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,13]<stdout>:local_ep_size = 4
[1,3]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:local_ep_size = 4
[1,3]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,3]<stdout>:Loading extension module transformer_inference...
[1,3]<stdout>:Time to load transformer_inference op: 0.03992772102355957 seconds
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:local_ep_size = 4
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:Using /home/amawa/.cache/torch_extensions as PyTorch extensions root...
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:local_ep_size = 4
[1,7]<stdout>:No modifications detected for re-loaded extension module transformer_inference, skipping build step...
[1,7]<stdout>:Loading extension module transformer_inference...
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:Time to load transformer_inference op: 0.04049205780029297 seconds
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 1, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:local_ep_size = 4
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:local_ep_size = 4
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:{'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:local_ep_size = 4
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,1]<stdout>:local_ep_size = 4
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:DeepSpeed Transformer Inference config is  [1,0]<stdout>:{'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,2]<stdout>:{'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:local_ep_size = 4
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:local_ep_size = 4
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:local_ep_size = 4
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,4]<stdout>:{'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:DeepSpeed Transformer Inference config is  [1,7]<stdout>:{'layer_id': 2, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,0]<stdout>:{'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:local_ep_size = 4
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,5]<stdout>:DeepSpeed Transformer Inference config is  [1,5]<stdout>:{'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,9]<stdout>:local_ep_size = 4
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,8]<stdout>:local_ep_size = 4
[1,13]<stdout>:local_ep_size = 4
[1,1]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:local_ep_size = 4
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:local_ep_size = 4
[1,6]<stdout>:local_ep_size = 4
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 3, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:local_ep_size = 4
[1,15]<stdout>:local_ep_size = 4
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:DeepSpeed Transformer Inference config is  [1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:{'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:local_ep_size = 4
[1,1]<stdout>:local_ep_size = 4
[1,0]<stdout>:DeepSpeed Transformer Inference config is  [1,0]<stdout>:{'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,10]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:moe, num_experts = True, 4, MoE(
[1,12]<stdout>:  (deepspeed_moe): MOELayer(
[1,12]<stdout>:    (gate): TopKGate(
[1,12]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,12]<stdout>:    )
[1,12]<stdout>:    (experts): Experts(
[1,12]<stdout>:      (deepspeed_experts): ModuleList(
[1,12]<stdout>:        (0): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (1): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (2): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:        (3): ParallelMLP(
[1,12]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,12]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,12]<stdout>:        )
[1,12]<stdout>:      )
[1,12]<stdout>:    )
[1,12]<stdout>:  )
[1,12]<stdout>:), 4
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,12]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,2]<stdout>:{'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:local_ep_size = 4
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,10]<stdout>:moe, num_experts = True, 4, MoE(
[1,10]<stdout>:  (deepspeed_moe): MOELayer(
[1,10]<stdout>:    (gate): TopKGate(
[1,10]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,10]<stdout>:    )
[1,10]<stdout>:    (experts): Experts(
[1,10]<stdout>:      (deepspeed_experts): ModuleList(
[1,10]<stdout>:        (0): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (1): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (2): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:        (3): ParallelMLP(
[1,10]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,10]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,10]<stdout>:        )
[1,10]<stdout>:      )
[1,10]<stdout>:    )
[1,10]<stdout>:  )
[1,10]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,10]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,6]<stdout>:
[1,12]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,14]<stdout>:local_ep_size = 4
[1,12]<stdout>:local_ep_size = 4
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:local_ep_size = 4
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,4]<stdout>:{'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:local_ep_size = 4
[1,7]<stdout>:DeepSpeed Transformer Inference config is  [1,7]<stdout>:{'layer_id': 4, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,0]<stdout>:local_ep_size = 4
[1,10]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,10]<stdout>:local_ep_size = 4
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:local_ep_size = 4
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,8]<stdout>:local_ep_size = 4
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:local_ep_size = 4
[1,5]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:DeepSpeed Transformer Inference config is  [1,1]<stdout>:{'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,2]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,2]<stdout>:
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4
[1,6]<stdout>:local_ep_size = 4
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,14]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:local_ep_size = 4
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 5, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:local_ep_size = 4
[1,11]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,14]<stdout>:moe, num_experts = True, 4, MoE(
[1,14]<stdout>:  (deepspeed_moe): MOELayer(
[1,14]<stdout>:    (gate): TopKGate(
[1,14]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,14]<stdout>:    )
[1,14]<stdout>:    (experts): Experts(
[1,14]<stdout>:      (deepspeed_experts): ModuleList(
[1,14]<stdout>:        (0): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (1): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (2): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:        (3): ParallelMLP(
[1,14]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,14]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,14]<stdout>:        )
[1,14]<stdout>:      )
[1,14]<stdout>:    )
[1,14]<stdout>:  )
[1,14]<stdout>:), 4
[1,14]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,12]<stdout>:[2021-12-09 02:24:29,829] [INFO] [engine.py:107:__init__] Place model to device: 4
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:{'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:DeepSpeed Transformer Inference config is  [1,0]<stdout>:{'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:local_ep_size = 4
[1,10]<stdout>:[2021-12-09 02:24:29,830] [INFO] [engine.py:107:__init__] Place model to device: 2
[1,1]<stdout>:local_ep_size = 4
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,13]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,8]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:local_ep_size = 4
[1,11]<stdout>:moe, num_experts = True, 4, MoE(
[1,11]<stdout>:  (deepspeed_moe): MOELayer(
[1,11]<stdout>:    (gate): TopKGate(
[1,11]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,11]<stdout>:    )
[1,11]<stdout>:    (experts): Experts(
[1,11]<stdout>:      (deepspeed_experts): ModuleList(
[1,11]<stdout>:        (0): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (1): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (2): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:        (3): ParallelMLP(
[1,11]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,11]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,11]<stdout>:        )
[1,11]<stdout>:      )
[1,11]<stdout>:    )
[1,11]<stdout>:  )
[1,11]<stdout>:), 4
[1,11]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,14]<stdout>:local_ep_size = 4
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,13]<stdout>:moe, num_experts = True, 4, MoE(
[1,13]<stdout>:  (deepspeed_moe): MOELayer(
[1,13]<stdout>:    (gate): TopKGate(
[1,13]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,13]<stdout>:    )
[1,13]<stdout>:    (experts): Experts(
[1,13]<stdout>:      (deepspeed_experts): ModuleList(
[1,13]<stdout>:        (0): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (1): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (2): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:        (3): ParallelMLP(
[1,13]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,13]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,13]<stdout>:        )
[1,13]<stdout>:      )
[1,13]<stdout>:    )
[1,13]<stdout>:  )
[1,13]<stdout>:), 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:moe, num_experts = True, 4, MoE(
[1,8]<stdout>:  (deepspeed_moe): MOELayer(
[1,8]<stdout>:    (gate): TopKGate(
[1,8]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,8]<stdout>:    )
[1,8]<stdout>:    (experts): Experts(
[1,8]<stdout>:      (deepspeed_experts): ModuleList(
[1,8]<stdout>:        (0): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (1): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (2): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:        (3): ParallelMLP(
[1,8]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,8]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,8]<stdout>:        )
[1,8]<stdout>:      )
[1,8]<stdout>:    )
[1,8]<stdout>:  )
[1,8]<stdout>:), 4
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,8]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,11]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:local_ep_size = 4
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,4]<stdout>:{'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,15]<stdout>:moe, num_experts = True, 4, MoE(
[1,15]<stdout>:  (deepspeed_moe): MOELayer(
[1,15]<stdout>:    (gate): TopKGate(
[1,15]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,15]<stdout>:    )
[1,15]<stdout>:    (experts): Experts(
[1,15]<stdout>:      (deepspeed_experts): ModuleList(
[1,15]<stdout>:        (0): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (1): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (2): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:        (3): ParallelMLP(
[1,15]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,15]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,15]<stdout>:        )
[1,15]<stdout>:      )
[1,15]<stdout>:    )
[1,15]<stdout>:  )
[1,15]<stdout>:), 4
[1,15]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,4]<stdout>:local_ep_size = 4
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,0]<stdout>:{'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:DeepSpeed Transformer Inference config is  [1,7]<stdout>:{'layer_id': 6, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:local_ep_size = 4
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,13]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,8]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:local_ep_size = 4
[1,13]<stdout>:local_ep_size = 4
[1,8]<stdout>:local_ep_size = 4
[1,5]<stdout>:DeepSpeed Transformer Inference config is  [1,5]<stdout>:{'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,1]<stdout>:
[1,2]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,15]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:local_ep_size = 4
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4
[1,6]<stdout>:local_ep_size = 4
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,14]<stdout>:[2021-12-09 02:24:29,838] [INFO] [engine.py:107:__init__] Place model to device: 6
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 7, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:local_ep_size = 4
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:DeepSpeed Transformer Inference config is  [1,0]<stdout>:{'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:local_ep_size = 4
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:{'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,11]<stdout>:[2021-12-09 02:24:29,841] [INFO] [engine.py:107:__init__] Place model to device: 3
[1,1]<stdout>:local_ep_size = 4
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,2]<stdout>:{'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,2]<stdout>:local_ep_size = 4
[1,12]<stdout>:> DeepSpeed Inference initialized
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,13]<stdout>:[2021-12-09 02:24:29,843] [INFO] [engine.py:107:__init__] Place model to device: 5
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,10]<stdout>:> DeepSpeed Inference initialized
[1,8]<stdout>:[2021-12-09 02:24:29,843] [INFO] [engine.py:107:__init__] Place model to device: 0
[1,15]<stdout>:[2021-12-09 02:24:29,844] [INFO] [engine.py:107:__init__] Place model to device: 7
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,9]<stdout>:moe, num_experts = True, 4, MoE(
[1,9]<stdout>:  (deepspeed_moe): MOELayer(
[1,9]<stdout>:    (gate): TopKGate(
[1,9]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,9]<stdout>:    )
[1,9]<stdout>:    (experts): Experts(
[1,9]<stdout>:      (deepspeed_experts): ModuleList(
[1,9]<stdout>:        (0): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (1): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (2): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:        (3): ParallelMLP(
[1,9]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,9]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,9]<stdout>:        )
[1,9]<stdout>:      )
[1,9]<stdout>:    )
[1,9]<stdout>:  )
[1,9]<stdout>:), 4
[1,9]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,6]<stdout>:
[1,12]<stdout>:NCCL version 2.8.4+cuda11.3
[1,10]<stdout>:NCCL version 2.8.4+cuda11.3
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,4]<stdout>:{'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:local_ep_size = 4
[1,7]<stdout>:DeepSpeed Transformer Inference config is  [1,7]<stdout>:{'layer_id': 8, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,0]<stdout>:{'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:local_ep_size = 4
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:local_ep_size = 4
[1,5]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,2]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,6]<stdout>:local_ep_size = 4
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 9, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:local_ep_size = 4
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:local_ep_size = 4
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,0]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:{'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:local_ep_size = 4
[1,2]<stdout>:{'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:local_ep_size = 4
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,9]<stdout>:[2021-12-09 02:24:29,855] [INFO] [engine.py:107:__init__] Place model to device: 1
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 10, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,7]<stdout>:
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,4]<stdout>:{'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,14]<stdout>:> DeepSpeed Inference initialized
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:local_ep_size = 4
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,0]<stdout>:local_ep_size = 4
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,5]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,14]<stdout>:NCCL version 2.8.4+cuda11.3
[1,2]<stdout>:DeepSpeed Transformer Inference config is  [1,2]<stdout>:{'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:local_ep_size = 4
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 11, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:local_ep_size = 4
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:local_ep_size = 4
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,4]<stdout>:
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:{'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:local_ep_size = 4
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:local_ep_size = 4
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 12, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,7]<stdout>:
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,4]<stdout>:{'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,0]<stdout>:{'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:local_ep_size = 4
[1,0]<stdout>:local_ep_size = 4
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,5]<stdout>:DeepSpeed Transformer Inference config is  [1,5]<stdout>:{'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:DeepSpeed Transformer Inference config is  [1,1]<stdout>:{'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:DeepSpeed Transformer Inference config is  [1,2]<stdout>:{'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,11]<stdout>:> DeepSpeed Inference initialized
[1,13]<stdout>:> DeepSpeed Inference initialized
[1,8]<stdout>:> DeepSpeed Inference initialized
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,15]<stdout>:> DeepSpeed Inference initialized
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:local_ep_size = 4
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 13, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:local_ep_size = 4
[1,11]<stdout>:NCCL version 2.8.4+cuda11.3
[1,13]<stdout>:NCCL version 2.8.4+cuda11.3
[1,8]<stdout>:NCCL version 2.8.4+cuda11.3
[1,15]<stdout>:NCCL version 2.8.4+cuda11.3
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:local_ep_size = 4
[1,0]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:{'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:local_ep_size = 4
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:local_ep_size = 4
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:DeepSpeed Transformer Inference config is  [1,6]<stdout>:{'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,7]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 14, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,4]<stdout>:{'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:local_ep_size = 4
[1,0]<stdout>:local_ep_size = 4
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,5]<stdout>:DeepSpeed Transformer Inference config is  [1,5]<stdout>:{'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,1]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,2]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4
[1,9]<stdout>:> DeepSpeed Inference initialized
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:local_ep_size = 4
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:{'layer_id': 15, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,9]<stdout>:NCCL version 2.8.4+cuda11.3
[1,7]<stdout>:local_ep_size = 4
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,4]<stdout>:
[1,5]<stdout>:local_ep_size = 4
[1,0]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:{'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,2]<stdout>:{'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:local_ep_size = 4
[1,2]<stdout>:local_ep_size = 4
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 16, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,0]<stdout>:{'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:local_ep_size = 4
[1,0]<stdout>:local_ep_size = 4
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,5]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,1]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,1]<stdout>:
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:local_ep_size = 4
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 17, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:local_ep_size = 4
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,0]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,0]<stdout>:
[1,5]<stdout>:local_ep_size = 4
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:{'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:local_ep_size = 4
[1,2]<stdout>:local_ep_size = 4
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,6]<stdout>:
[1,7]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 18, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,4]<stdout>:{'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:local_ep_size = 4
[1,0]<stdout>:local_ep_size = 4
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,5]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:local_ep_size = 4
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 19, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:local_ep_size = 4
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,0]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:local_ep_size = 4
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,2]<stdout>:{'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:{'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:local_ep_size = 4
[1,1]<stdout>:local_ep_size = 4
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,7]<stdout>:DeepSpeed Transformer Inference config is  [1,7]<stdout>:{'layer_id': 20, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,0]<stdout>:{'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:local_ep_size = 4
[1,0]<stdout>:local_ep_size = 4
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,5]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:DeepSpeed Transformer Inference config is  [1,2]<stdout>:{'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:local_ep_size = 4
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 21, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:local_ep_size = 4
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,0]<stdout>:DeepSpeed Transformer Inference config is  [1,0]<stdout>:{'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:local_ep_size = 4
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,2]<stdout>:{'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:{'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:local_ep_size = 4
[1,1]<stdout>:local_ep_size = 4
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,3]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,6]<stdout>:
[1,7]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 22, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,4]<stdout>:{'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,0]<stdout>:{'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:local_ep_size = 4
[1,0]<stdout>:local_ep_size = 4
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,5]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,2]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,1]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:local_ep_size = 4
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 23, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:local_ep_size = 4
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,0]<stdout>:DeepSpeed Transformer Inference config is  [1,0]<stdout>:{'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:local_ep_size = 4
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:local_ep_size = 4
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:{'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:local_ep_size = 4
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,6]<stdout>:
[1,7]<stdout>:DeepSpeed Transformer Inference config is  [1,7]<stdout>:{'layer_id': 24, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,0]<stdout>:{'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,4]<stdout>:{'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,0]<stdout>:local_ep_size = 4
[1,4]<stdout>:local_ep_size = 4
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,2]<stdout>:DeepSpeed Transformer Inference config is  [1,2]<stdout>:{'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,5]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:local_ep_size = 4
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:local_ep_size = 4
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 25, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,7]<stdout>:local_ep_size = 4
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,2]<stdout>:{'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:local_ep_size = 4
[1,0]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:local_ep_size = 4
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:{'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:local_ep_size = 4
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,2]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 26, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,4]<stdout>:{'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,0]<stdout>:local_ep_size = 4
[1,4]<stdout>:local_ep_size = 4
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,5]<stdout>:DeepSpeed Transformer Inference config is  [1,5]<stdout>:{'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,1]<stdout>:
[1,3]<stdout>:local_ep_size = 4
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:local_ep_size = 4
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,2]<stdout>:{'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:local_ep_size = 4
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 27, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,7]<stdout>:local_ep_size = 4
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:local_ep_size = 4
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:{'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:local_ep_size = 4
[1,6]<stdout>:DeepSpeed Transformer Inference config is  [1,6]<stdout>:{'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,0]<stdout>:moe, num_experts = True, 4, MoE(
[1,0]<stdout>:  (deepspeed_moe): MOELayer(
[1,0]<stdout>:    (gate): TopKGate(
[1,0]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,0]<stdout>:    )
[1,0]<stdout>:    (experts): Experts(
[1,0]<stdout>:      (deepspeed_experts): ModuleList(
[1,0]<stdout>:        (0): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (1): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (2): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:        (3): ParallelMLP(
[1,0]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,0]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,0]<stdout>:        )
[1,0]<stdout>:      )
[1,0]<stdout>:    )
[1,0]<stdout>:  )
[1,0]<stdout>:), 4
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,0]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:DeepSpeed Transformer Inference config is  [1,2]<stdout>:{'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,7]<stdout>:DeepSpeed Transformer Inference config is  [1,7]<stdout>:{'layer_id': 28, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,0]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,0]<stdout>:local_ep_size = 4
[1,4]<stdout>:local_ep_size = 4
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,6]<stdout>:local_ep_size = 4
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,2]<stdout>:{'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4
[1,2]<stdout>:local_ep_size = 4
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 29, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:local_ep_size = 4
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,4]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:local_ep_size = 4
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,5]<stdout>:{'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,5]<stdout>:local_ep_size = 4
[1,0]<stdout>:[2021-12-09 02:24:29,972] [INFO] [engine.py:107:__init__] Place model to device: 0
[1,2]<stdout>:DeepSpeed Transformer Inference config is  [1,2]<stdout>:{'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,4]<stdout>:moe, num_experts = True, 4, MoE(
[1,4]<stdout>:  (deepspeed_moe): MOELayer(
[1,4]<stdout>:    (gate): TopKGate(
[1,4]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,4]<stdout>:    )
[1,4]<stdout>:    (experts): Experts(
[1,4]<stdout>:      (deepspeed_experts): ModuleList(
[1,4]<stdout>:        (0): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (1): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (2): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:        (3): ParallelMLP(
[1,4]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,4]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,4]<stdout>:        )
[1,4]<stdout>:      )
[1,4]<stdout>:    )
[1,4]<stdout>:  )
[1,4]<stdout>:), 4
[1,3]<stdout>:{'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,6]<stdout>:moe, num_experts = True, 4, MoE(
[1,6]<stdout>:  (deepspeed_moe): MOELayer(
[1,6]<stdout>:    (gate): TopKGate(
[1,6]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,6]<stdout>:    )
[1,6]<stdout>:    (experts): Experts(
[1,6]<stdout>:      (deepspeed_experts): ModuleList(
[1,6]<stdout>:        (0): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (1): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (2): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:        (3): ParallelMLP(
[1,6]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,6]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,6]<stdout>:        )
[1,6]<stdout>:      )
[1,6]<stdout>:    )
[1,6]<stdout>:  )
[1,6]<stdout>:), 4
[1,4]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,6]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,2]<stdout>:moe, num_experts = True, 4, MoE(
[1,2]<stdout>:  (deepspeed_moe): MOELayer(
[1,2]<stdout>:    (gate): TopKGate(
[1,2]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,2]<stdout>:    )
[1,2]<stdout>:    (experts): Experts(
[1,2]<stdout>:      (deepspeed_experts): ModuleList(
[1,2]<stdout>:        (0): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (1): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (2): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:        (3): ParallelMLP(
[1,2]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,2]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,2]<stdout>:        )
[1,2]<stdout>:      )
[1,2]<stdout>:    )
[1,2]<stdout>:  )
[1,2]<stdout>:), 4
[1,2]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,7]<stdout>:DeepSpeed Transformer Inference config is  [1,7]<stdout>:{'layer_id': 30, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,4]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,6]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,6]<stdout>:{'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,4]<stdout>:local_ep_size = 4
[1,6]<stdout>:local_ep_size = 4
[1,2]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,2]<stdout>:{'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,2]<stdout>:local_ep_size = 4
[1,5]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,3]<stdout>:{'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:local_ep_size = 4
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 31, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:local_ep_size = 4
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}[1,1]<stdout>:
[1,1]<stdout>:local_ep_size = 4
[1,6]<stdout>:[2021-12-09 02:24:29,982] [INFO] [engine.py:107:__init__] Place model to device: 6
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:local_ep_size = 4
[1,4]<stdout>:[2021-12-09 02:24:29,983] [INFO] [engine.py:107:__init__] Place model to device: 4
[1,2]<stdout>:[2021-12-09 02:24:29,984] [INFO] [engine.py:107:__init__] Place model to device: 2
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,0]<stdout>:> DeepSpeed Inference initialized
[1,1]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,7]<stdout>:DeepSpeed Transformer Inference config is  [1,7]<stdout>:{'layer_id': 32, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,1]<stdout>:moe, num_experts = True, 4, MoE(
[1,1]<stdout>:  (deepspeed_moe): MOELayer(
[1,1]<stdout>:    (gate): TopKGate(
[1,1]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,1]<stdout>:    )
[1,1]<stdout>:    (experts): Experts(
[1,1]<stdout>:      (deepspeed_experts): ModuleList(
[1,1]<stdout>:        (0): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (1): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (2): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:        (3): ParallelMLP(
[1,1]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,1]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,1]<stdout>:        )
[1,1]<stdout>:      )
[1,1]<stdout>:    )
[1,1]<stdout>:  )
[1,1]<stdout>:), 4
[1,1]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,5]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4
[1,1]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,1]<stdout>:local_ep_size = 4
[1,5]<stdout>:moe, num_experts = True, 4, MoE(
[1,5]<stdout>:  (deepspeed_moe): MOELayer(
[1,5]<stdout>:    (gate): TopKGate(
[1,5]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,5]<stdout>:    )
[1,5]<stdout>:    (experts): Experts(
[1,5]<stdout>:      (deepspeed_experts): ModuleList(
[1,5]<stdout>:        (0): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (1): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (2): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:        (3): ParallelMLP(
[1,5]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,5]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,5]<stdout>:        )
[1,5]<stdout>:      )
[1,5]<stdout>:    )
[1,5]<stdout>:  )
[1,5]<stdout>:), 4
[1,5]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 33, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:local_ep_size = 4
[1,5]<stdout>:DeepSpeed MoE Transformer Inference config is  {'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,5]<stdout>:local_ep_size = 4
[1,3]<stdout>:DeepSpeed Transformer Inference config is  [1,3]<stdout>:{'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}
[1,1]<stdout>:[2021-12-09 02:24:29,998] [INFO] [engine.py:107:__init__] Place model to device: 1
[1,3]<stdout>:moe, num_experts = True, 4, MoE(
[1,3]<stdout>:  (deepspeed_moe): MOELayer(
[1,3]<stdout>:    (gate): TopKGate(
[1,3]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,3]<stdout>:    )
[1,3]<stdout>:    (experts): Experts(
[1,3]<stdout>:      (deepspeed_experts): ModuleList(
[1,3]<stdout>:        (0): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (1): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (2): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:        (3): ParallelMLP(
[1,3]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,3]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,3]<stdout>:        )
[1,3]<stdout>:      )
[1,3]<stdout>:    )
[1,3]<stdout>:  )
[1,3]<stdout>:), 4
[1,7]<stdout>:DeepSpeed Transformer Inference config is  {'layer_id': 34, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'return_tuple': False, 'specialized_mode': False}[1,3]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,7]<stdout>:
[1,7]<stdout>:moe, num_experts = True, 4, MoE(
[1,7]<stdout>:  (deepspeed_moe): MOELayer(
[1,7]<stdout>:    (gate): TopKGate(
[1,7]<stdout>:      (wg): Linear(in_features=3072, out_features=128, bias=False)
[1,7]<stdout>:    )
[1,7]<stdout>:    (experts): Experts(
[1,7]<stdout>:      (deepspeed_experts): ModuleList(
[1,7]<stdout>:        (0): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (1): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (2): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:        (3): ParallelMLP(
[1,7]<stdout>:          (dense_h_to_4h): ColumnParallelLinear()
[1,7]<stdout>:          (dense_4h_to_h): RowParallelLinear()
[1,7]<stdout>:        )
[1,7]<stdout>:      )
[1,7]<stdout>:    )
[1,7]<stdout>:  )
[1,7]<stdout>:), 4
[1,7]<stdout>:local_ep_size = 4, ep_world_size = 32, ep_grou = None
[1,3]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,3]<stdout>:{'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,3]<stdout>:local_ep_size = 4
[1,5]<stdout>:[2021-12-09 02:24:30,002] [INFO] [engine.py:107:__init__] Place model to device: 5
[1,7]<stdout>:DeepSpeed MoE Transformer Inference config is  [1,7]<stdout>:{'layer_id': 35, 'hidden_size': 3072, 'intermediate_size': 12288, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-12, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 256, 'return_tuple': True, 'specialized_mode': False, 'moe_experts': 4, 'k': 1, 'capacity_factor': 1.0, 'eval_capacity_factor': 1.0, 'min_capacity': 1, 'noisy_gate_policy': None, 'drop_tokens': True, 'use_rts': False, 'global_experts': 128}
[1,7]<stdout>:local_ep_size = 4
[1,3]<stdout>:[2021-12-09 02:24:30,009] [INFO] [engine.py:107:__init__] Place model to device: 3
[1,6]<stdout>:> DeepSpeed Inference initialized
[1,2]<stdout>:> DeepSpeed Inference initialized
[1,7]<stdout>:[2021-12-09 02:24:30,011] [INFO] [engine.py:107:__init__] Place model to device: 7
[1,4]<stdout>:> DeepSpeed Inference initialized
[1,6]<stdout>:NCCL version 2.8.4+cuda11.3
[1,2]<stdout>:NCCL version 2.8.4+cuda11.3
[1,4]<stdout>:NCCL version 2.8.4+cuda11.3
[1,1]<stdout>:> DeepSpeed Inference initialized
[1,1]<stdout>:NCCL version 2.8.4+cuda11.3
[1,5]<stdout>:> DeepSpeed Inference initialized
[1,5]<stdout>:NCCL version 2.8.4+cuda11.3
[1,3]<stdout>:> DeepSpeed Inference initialized
[1,3]<stdout>:NCCL version 2.8.4+cuda11.3
[1,7]<stdout>:> DeepSpeed Inference initialized
[1,7]<stdout>:NCCL version 2.8.4+cuda11.3
[1,17]<stdout>:
[1,17]<stdout>:webxt6cb30000AB:38749:39276 [1] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,17]<stdout>:
[1,17]<stdout>:webxt6cb30000AB:38749:39276 [1] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,30]<stdout>:
[1,30]<stdout>:webxt6cb300008U:38816:39323 [6] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,30]<stdout>:
[1,30]<stdout>:webxt6cb300008U:38816:39323 [6] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,31]<stdout>:
[1,31]<stdout>:webxt6cb300008U:38817:39321 [7] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,31]<stdout>:
[1,31]<stdout>:webxt6cb300008U:38817:39321 [7] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,21]<stdout>:
[1,21]<stdout>:webxt6cb30000AB:38753:39281 [5] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,21]<stdout>:
[1,21]<stdout>:webxt6cb30000AB:38753:39281 [5] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,16]<stdout>:
[1,16]<stdout>:webxt6cb30000AB:38748:39277 [0] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,16]<stdout>:
[1,16]<stdout>:webxt6cb30000AB:38748:39277 [0] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,28]<stdout>:
[1,28]<stdout>:webxt6cb300008U:38814:39337 [4] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,28]<stdout>:
[1,28]<stdout>:webxt6cb300008U:38814:39337 [4] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,18]<stdout>:
[1,18]<stdout>:webxt6cb30000AB:38750:39284 [2] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,18]<stdout>:
[1,18]<stdout>:webxt6cb30000AB:38750:39284 [2] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,20]<stdout>:
[1,20]<stdout>:webxt6cb30000AB:38752:39287 [4] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,20]<stdout>:
[1,20]<stdout>:webxt6cb30000AB:38752:39287 [4] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,24]<stdout>:
[1,24]<stdout>:webxt6cb300008U:38810:39325 [0] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,24]<stdout>:
[1,24]<stdout>:webxt6cb300008U:38810:39325 [0] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,29]<stdout>:
[1,29]<stdout>:webxt6cb300008U:38815:39330 [5] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,29]<stdout>:
[1,29]<stdout>:webxt6cb300008U:38815:39330 [5] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,23]<stdout>:
[1,23]<stdout>:webxt6cb30000AB:38755:39290 [7] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,23]<stdout>:
[1,23]<stdout>:webxt6cb30000AB:38755:39290 [7] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,22]<stdout>:
[1,22]<stdout>:webxt6cb30000AB:38754:39292 [6] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,22]<stdout>:
[1,22]<stdout>:webxt6cb30000AB:38754:39292 [6] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,25]<stdout>:
[1,25]<stdout>:webxt6cb300008U:38811:39336 [1] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,25]<stdout>:
[1,25]<stdout>:webxt6cb300008U:38811:39336 [1] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,19]<stdout>:
[1,19]<stdout>:webxt6cb30000AB:38751:39296 [3] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,19]<stdout>:
[1,19]<stdout>:webxt6cb30000AB:38751:39296 [3] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,26]<stdout>:
[1,26]<stdout>:webxt6cb300008U:38812:39338 [2] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,26]<stdout>:
[1,26]<stdout>:webxt6cb300008U:38812:39338 [2] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,27]<stdout>:
[1,27]<stdout>:webxt6cb300008U:38813:39332 [3] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,27]<stdout>:
[1,27]<stdout>:webxt6cb300008U:38813:39332 [3] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,12]<stdout>:
[1,12]<stdout>:webxt6cb300009V:67898:68401 [4] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,12]<stdout>:
[1,12]<stdout>:webxt6cb300009V:67898:68401 [4] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,10]<stdout>:
[1,10]<stdout>:webxt6cb300009V:67896:68403 [2] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,10]<stdout>:
[1,10]<stdout>:webxt6cb300009V:67896:68403 [2] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,14]<stdout>:
[1,14]<stdout>:webxt6cb300009V:67900:68407 [6] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,14]<stdout>:
[1,14]<stdout>:webxt6cb300009V:67900:68407 [6] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,9]<stdout>:
[1,9]<stdout>:webxt6cb300009V:67895:68422 [1] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,9]<stdout>:
[1,9]<stdout>:webxt6cb300009V:67895:68422 [1] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,8]<stdout>:
[1,8]<stdout>:webxt6cb300009V:67894:68415 [0] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,8]<stdout>:
[1,8]<stdout>:webxt6cb300009V:67894:68415 [0] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,11]<stdout>:
[1,11]<stdout>:webxt6cb300009V:67897:68413 [3] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,11]<stdout>:
[1,11]<stdout>:webxt6cb300009V:67897:68413 [3] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,13]<stdout>:
[1,13]<stdout>:webxt6cb300009V:67899:68414 [5] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,13]<stdout>:
[1,13]<stdout>:webxt6cb300009V:67899:68414 [5] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,15]<stdout>:
[1,15]<stdout>:webxt6cb300009V:67901:68416 [7] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,15]<stdout>:
[1,15]<stdout>:webxt6cb300009V:67901:68416 [7] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,0]<stdout>:
[1,0]<stdout>:webxt6cb30000A2:63090:63672 [0] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,0]<stdout>:
[1,0]<stdout>:webxt6cb30000A2:63090:63672 [0] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,2]<stdout>:
[1,2]<stdout>:webxt6cb30000A2:63092:63678 [2] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,2]<stdout>:
[1,2]<stdout>:webxt6cb30000A2:63092:63678 [2] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,4]<stdout>:
[1,4]<stdout>:webxt6cb30000A2:63094:63679 [4] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,4]<stdout>:
[1,4]<stdout>:webxt6cb30000A2:63094:63679 [4] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,6]<stdout>:
[1,6]<stdout>:webxt6cb30000A2:63096:63677 [6] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,6]<stdout>:
[1,6]<stdout>:webxt6cb30000A2:63096:63677 [6] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,1]<stdout>:
[1,1]<stdout>:webxt6cb30000A2:63091:63684 [1] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,1]<stdout>:
[1,1]<stdout>:webxt6cb30000A2:63091:63684 [1] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,5]<stdout>:
[1,5]<stdout>:webxt6cb30000A2:63095:63687 [5] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,5]<stdout>:
[1,5]<stdout>:webxt6cb30000A2:63095:63687 [5] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,3]<stdout>:
[1,3]<stdout>:webxt6cb30000A2:63093:63690 [3] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,3]<stdout>:
[1,3]<stdout>:webxt6cb30000A2:63093:63690 [3] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,7]<stdout>:
[1,7]<stdout>:webxt6cb30000A2:63097:63693 [7] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,7]<stdout>:
[1,7]<stdout>:webxt6cb30000A2:63097:63693 [7] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,17]<stdout>:test: range(0, 32)
[1,30]<stdout>:test: range(0, 32)
[1,20]<stdout>:test: range(0, 32)
[1,21]<stdout>:test: range(0, 32)
[1,28]<stdout>:test: range(0, 32)
[1,16]<stdout>:test: range(0, 32)
[1,31]<stdout>:test: range(0, 32)
[1,24]<stdout>:test: range(0, 32)
[1,25]<stdout>:test: range(0, 32)
[1,18]<stdout>:test: range(0, 32)
[1,29]<stdout>:test: range(0, 32)
[1,23]<stdout>:test: range(0, 32)
[1,19]<stdout>:test: range(0, 32)
[1,22]<stdout>:test: range(0, 32)
[1,26]<stdout>:test: range(0, 32)
[1,27]<stdout>:test: range(0, 32)
[1,12]<stdout>:test: range(0, 32)
[1,10]<stdout>:test: range(0, 32)
[1,14]<stdout>:test: range(0, 32)
[1,8]<stdout>:test: range(0, 32)
[1,13]<stdout>:test: range(0, 32)
[1,9]<stdout>:test: range(0, 32)
[1,11]<stdout>:test: range(0, 32)
[1,15]<stdout>:test: range(0, 32)
[1,0]<stdout>:test: range(0, 32)
[1,6]<stdout>:test: range(0, 32)
[1,2]<stdout>:test: range(0, 32)
[1,4]<stdout>:test: range(0, 32)
[1,1]<stdout>:test: range(0, 32)
[1,7]<stdout>:test: range(0, 32)
[1,3]<stdout>:test: range(0, 32)
[1,5]<stdout>:test: range(0, 32)
[1,9]<stdout>:
[1,9]<stdout>:webxt6cb300009V:67895:68463 [1] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,9]<stdout>:
[1,9]<stdout>:webxt6cb300009V:67895:68463 [1] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,25]<stdout>:
[1,25]<stdout>:webxt6cb300008U:38811:39383 [1] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,25]<stdout>:
[1,25]<stdout>:webxt6cb300008U:38811:39383 [1] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,28]<stdout>:
[1,28]<stdout>:webxt6cb300008U:38814:39388 [4] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,28]<stdout>:
[1,28]<stdout>:webxt6cb300008U:38814:39388 [4] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,17]<stdout>:
[1,17]<stdout>:webxt6cb30000AB:38749:39338 [1] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,17]<stdout>:
[1,17]<stdout>:webxt6cb30000AB:38749:39338 [1] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,31]<stdout>:
[1,31]<stdout>:webxt6cb300008U:38817:39392 [7] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,31]<stdout>:
[1,31]<stdout>:webxt6cb300008U:38817:39392 [7] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,0]<stdout>:
[1,0]<stdout>:webxt6cb30000A2:63090:63736 [0] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,0]<stdout>:
[1,0]<stdout>:webxt6cb30000A2:63090:63736 [0] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,16]<stdout>:
[1,16]<stdout>:webxt6cb30000AB:38748:39344 [0] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,16]<stdout>:
[1,16]<stdout>:webxt6cb30000AB:38748:39344 [0] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,24]<stdout>:
[1,24]<stdout>:webxt6cb300008U:38810:39390 [0] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,24]<stdout>:
[1,24]<stdout>:webxt6cb300008U:38810:39390 [0] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,10]<stdout>:
[1,10]<stdout>:webxt6cb300009V:67896:68470 [2] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,10]<stdout>:
[1,10]<stdout>:webxt6cb300009V:67896:68470 [2] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,26]<stdout>:
[1,26]<stdout>:webxt6cb300008U:38812:39394 [2] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,26]<stdout>:
[1,26]<stdout>:webxt6cb300008U:38812:39394 [2] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,23]<stdout>:
[1,23]<stdout>:webxt6cb30000AB:38755:39349 [7] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,23]<stdout>:
[1,23]<stdout>:webxt6cb30000AB:38755:39349 [7] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,1]<stdout>:
[1,1]<stdout>:webxt6cb30000A2:63091:63735 [1] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,1]<stdout>:
[1,1]<stdout>:webxt6cb30000A2:63091:63735 [1] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,14]<stdout>:
[1,14]<stdout>:webxt6cb300009V:67900:68471 [6] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,14]<stdout>:
[1,14]<stdout>:webxt6cb300009V:67900:68471 [6] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,30]<stdout>:
[1,30]<stdout>:webxt6cb300008U:38816:39393 [6] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,30]<stdout>:
[1,30]<stdout>:webxt6cb300008U:38816:39393 [6] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,22]<stdout>:
[1,22]<stdout>:webxt6cb30000AB:38754:39342 [6] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,22]<stdout>:
[1,22]<stdout>:webxt6cb30000AB:38754:39342 [6] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,7]<stdout>:
[1,7]<stdout>:webxt6cb30000A2:63097:63741 [7] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,7]<stdout>:
[1,7]<stdout>:webxt6cb30000A2:63097:63741 [7] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,27]<stdout>:
[1,27]<stdout>:webxt6cb300008U:38813:39396 [3] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,27]<stdout>:
[1,27]<stdout>:webxt6cb300008U:38813:39396 [3] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,15]<stdout>:
[1,15]<stdout>:webxt6cb300009V:67901:68473 [7] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,15]<stdout>:
[1,15]<stdout>:webxt6cb300009V:67901:68473 [7] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,29]<stdout>:
[1,29]<stdout>:webxt6cb300008U:38815:39401 [5] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,29]<stdout>:
[1,29]<stdout>:webxt6cb300008U:38815:39401 [5] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,21]<stdout>:
[1,21]<stdout>:webxt6cb30000AB:38753:39350 [5] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,21]<stdout>:
[1,21]<stdout>:webxt6cb30000AB:38753:39350 [5] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,13]<stdout>:
[1,13]<stdout>:webxt6cb300009V:67899:68476 [5] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,13]<stdout>:
[1,13]<stdout>:webxt6cb300009V:67899:68476 [5] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,20]<stdout>:
[1,20]<stdout>:webxt6cb30000AB:38752:39348 [4] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,20]<stdout>:
[1,20]<stdout>:webxt6cb30000AB:38752:39348 [4] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,5]<stdout>:
[1,5]<stdout>:webxt6cb30000A2:63095:63748 [5] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,5]<stdout>:
[1,5]<stdout>:webxt6cb30000A2:63095:63748 [5] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,12]<stdout>:
[1,12]<stdout>:webxt6cb300009V:67898:68474 [4] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,12]<stdout>:
[1,12]<stdout>:webxt6cb300009V:67898:68474 [4] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,19]<stdout>:
[1,19]<stdout>:webxt6cb30000AB:38751:39351 [3] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,19]<stdout>:
[1,19]<stdout>:webxt6cb30000AB:38751:39351 [3] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,8]<stdout>:
[1,8]<stdout>:webxt6cb300009V:67894:68469 [0] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,8]<stdout>:
[1,8]<stdout>:webxt6cb300009V:67894:68469 [0] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,6]<stdout>:
[1,6]<stdout>:webxt6cb30000A2:63096:63743 [6] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,6]<stdout>:
[1,6]<stdout>:webxt6cb30000A2:63096:63743 [6] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,18]<stdout>:
[1,18]<stdout>:webxt6cb30000AB:38750:39353 [2] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,18]<stdout>:
[1,18]<stdout>:webxt6cb30000AB:38750:39353 [2] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,11]<stdout>:
[1,11]<stdout>:webxt6cb300009V:67897:68481 [3] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,11]<stdout>:
[1,11]<stdout>:webxt6cb300009V:67897:68481 [3] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,4]<stdout>:
[1,4]<stdout>:webxt6cb30000A2:63094:63747 [4] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,4]<stdout>:
[1,4]<stdout>:webxt6cb30000A2:63094:63747 [4] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,2]<stdout>:
[1,2]<stdout>:webxt6cb30000A2:63092:63750 [2] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,2]<stdout>:
[1,2]<stdout>:webxt6cb30000A2:63092:63750 [2] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,3]<stdout>:
[1,3]<stdout>:webxt6cb30000A2:63093:63749 [3] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,3]<stdout>:
[1,3]<stdout>:webxt6cb30000A2:63093:63749 [3] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,25]<stdout>:
[1,25]<stdout>:webxt6cb300008U:38811:39409 [1] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,25]<stdout>:
[1,25]<stdout>:webxt6cb300008U:38811:39409 [1] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,9]<stdout>:
[1,9]<stdout>:webxt6cb300009V:67895:68488 [1] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,9]<stdout>:
[1,9]<stdout>:webxt6cb300009V:67895:68488 [1] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,28]<stdout>:
[1,28]<stdout>:webxt6cb300008U:38814:39414 [4] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,28]<stdout>:
[1,28]<stdout>:webxt6cb300008U:38814:39414 [4] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,31]<stdout>:
[1,31]<stdout>:webxt6cb300008U:38817:39418 [7] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,31]<stdout>:
[1,31]<stdout>:webxt6cb300008U:38817:39418 [7] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,24]<stdout>:
[1,24]<stdout>:webxt6cb300008U:38810:39421 [0] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,24]<stdout>:
[1,24]<stdout>:webxt6cb300008U:38810:39421 [0] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,26]<stdout>:
[1,26]<stdout>:webxt6cb300008U:38812:39424 [2] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,26]<stdout>:
[1,26]<stdout>:webxt6cb300008U:38812:39424 [2] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,17]<stdout>:
[1,17]<stdout>:webxt6cb30000AB:38749:39365 [1] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,17]<stdout>:
[1,17]<stdout>:webxt6cb30000AB:38749:39365 [1] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,10]<stdout>:
[1,10]<stdout>:webxt6cb300009V:67896:68493 [2] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,10]<stdout>:
[1,10]<stdout>:webxt6cb300009V:67896:68493 [2] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,16]<stdout>:
[1,16]<stdout>:webxt6cb30000AB:38748:39368 [0] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,16]<stdout>:
[1,16]<stdout>:webxt6cb30000AB:38748:39368 [0] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,30]<stdout>:
[1,30]<stdout>:webxt6cb300008U:38816:39428 [6] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,30]<stdout>:
[1,30]<stdout>:webxt6cb300008U:38816:39428 [6] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,0]<stdout>:
[1,0]<stdout>:webxt6cb30000A2:63090:63761 [0] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,0]<stdout>:
[1,0]<stdout>:webxt6cb30000A2:63090:63761 [0] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,27]<stdout>:
[1,27]<stdout>:webxt6cb300008U:38813:39433 [3] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,27]<stdout>:
[1,27]<stdout>:webxt6cb300008U:38813:39433 [3] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,29]<stdout>:
[1,29]<stdout>:webxt6cb300008U:38815:39436 [5] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,29]<stdout>:
[1,29]<stdout>:webxt6cb300008U:38815:39436 [5] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,23]<stdout>:
[1,23]<stdout>:webxt6cb30000AB:38755:39372 [7] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,23]<stdout>:
[1,23]<stdout>:webxt6cb30000AB:38755:39372 [7] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,14]<stdout>:
[1,14]<stdout>:webxt6cb300009V:67900:68497 [6] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,14]<stdout>:
[1,14]<stdout>:webxt6cb300009V:67900:68497 [6] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,1]<stdout>:
[1,1]<stdout>:webxt6cb30000A2:63091:63765 [1] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,1]<stdout>:
[1,1]<stdout>:webxt6cb30000A2:63091:63765 [1] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,15]<stdout>:
[1,15]<stdout>:webxt6cb300009V:67901:68501 [7] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,15]<stdout>:
[1,15]<stdout>:webxt6cb300009V:67901:68501 [7] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,22]<stdout>:
[1,22]<stdout>:webxt6cb30000AB:38754:39376 [6] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,22]<stdout>:
[1,22]<stdout>:webxt6cb30000AB:38754:39376 [6] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,7]<stdout>:
[1,7]<stdout>:webxt6cb30000A2:63097:63767 [7] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,7]<stdout>:
[1,7]<stdout>:webxt6cb30000A2:63097:63767 [7] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,21]<stdout>:
[1,21]<stdout>:webxt6cb30000AB:38753:39379 [5] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,21]<stdout>:
[1,21]<stdout>:webxt6cb30000AB:38753:39379 [5] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,13]<stdout>:
[1,13]<stdout>:webxt6cb300009V:67899:68504 [5] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,13]<stdout>:
[1,13]<stdout>:webxt6cb300009V:67899:68504 [5] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,18]<stdout>:
[1,18]<stdout>:webxt6cb30000AB:38750:39391 [2] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,18]<stdout>:
[1,18]<stdout>:webxt6cb30000AB:38750:39391 [2] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,5]<stdout>:
[1,5]<stdout>:webxt6cb30000A2:63095:63772 [5] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,5]<stdout>:
[1,5]<stdout>:webxt6cb30000A2:63095:63772 [5] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,20]<stdout>:
[1,20]<stdout>:webxt6cb30000AB:38752:39383 [4] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,20]<stdout>:
[1,20]<stdout>:webxt6cb30000AB:38752:39383 [4] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,12]<stdout>:
[1,12]<stdout>:webxt6cb300009V:67898:68508 [4] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,12]<stdout>:
[1,12]<stdout>:webxt6cb300009V:67898:68508 [4] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,19]<stdout>:
[1,19]<stdout>:webxt6cb30000AB:38751:39388 [3] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,19]<stdout>:
[1,19]<stdout>:webxt6cb30000AB:38751:39388 [3] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,6]<stdout>:
[1,6]<stdout>:webxt6cb30000A2:63096:63775 [6] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,6]<stdout>:
[1,6]<stdout>:webxt6cb30000A2:63096:63775 [6] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,8]<stdout>:
[1,8]<stdout>:webxt6cb300009V:67894:68513 [0] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,8]<stdout>:
[1,8]<stdout>:webxt6cb300009V:67894:68513 [0] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,11]<stdout>:
[1,11]<stdout>:webxt6cb300009V:67897:68516 [3] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,11]<stdout>:
[1,11]<stdout>:webxt6cb300009V:67897:68516 [3] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,4]<stdout>:
[1,4]<stdout>:webxt6cb30000A2:63094:63779 [4] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,4]<stdout>:
[1,4]<stdout>:webxt6cb30000A2:63094:63779 [4] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,2]<stdout>:
[1,2]<stdout>:webxt6cb30000A2:63092:63783 [2] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,2]<stdout>:
[1,2]<stdout>:webxt6cb30000A2:63092:63783 [2] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,3]<stdout>:
[1,3]<stdout>:webxt6cb30000A2:63093:63787 [3] graph/topo.cc:675 NCCL WARN SCCL: ngpus set in the SCCL algo (32) doesn't match the communicator ngpus (1)
[1,3]<stdout>:
[1,3]<stdout>:webxt6cb30000A2:63093:63787 [3] graph/topo.cc:1036 NCCL WARN SCCL: algorithm /home/amawa/a2a-32.xml failed to initialize. Will be ignored.
[1,0]<stdout>:====== latency stats {0} ====== 
[1,0]<stdout>:	Avg Latency:  1160.39 ms
[1,0]<stdout>:	P50 Latency:  1160.62 ms
[1,0]<stdout>:	P90 Latency:  1164.31 ms
[1,0]<stdout>:	P95 Latency:  1164.31 ms
[1,0]<stdout>:	P99 Latency:  1164.31 ms
[1,0]<stdout>:	999 Latency:  1164.31 ms
[1,0]<stdout>:====== latency stats {0} ====== model_latencies
[1,0]<stdout>:	Avg Latency:    32.08 ms
[1,0]<stdout>:	P50 Latency:    31.78 ms
[1,0]<stdout>:	P90 Latency:    33.41 ms
[1,0]<stdout>:	P95 Latency:    33.85 ms
[1,0]<stdout>:	P99 Latency:    35.57 ms
[1,0]<stdout>:	999 Latency:    38.64 ms
[1,0]<stdout>:====== latency stats {0} ====== single_token_latency
[1,0]<stdout>:	Avg Latency:    39.91 ms
[1,0]<stdout>:	P50 Latency:    39.61 ms
[1,0]<stdout>:	P90 Latency:    41.32 ms
[1,0]<stdout>:	P95 Latency:    41.79 ms
[1,0]<stdout>:	P99 Latency:    43.37 ms[1,0]<stdout>:
[1,0]<stdout>:	999 Latency:    46.47 ms
