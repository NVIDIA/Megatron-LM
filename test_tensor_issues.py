#!/usr/bin/env python3
"""
æµ‹è¯•tensoræ”¶é›†é—®é¢˜
"""

import sys
import os
sys.path.append('/data/charles/codes/Megatron-LM')

def test_layer_idx_detection():
    """æµ‹è¯•layer_idxæ£€æµ‹é€»è¾‘"""
    print("æµ‹è¯•layer_idxæ£€æµ‹é€»è¾‘...")
    
    import inspect
    
    class MockTransformerLayer:
        def __init__(self, layer_number):
            self.layer_number = layer_number
    
    class MockMLP:
        def __init__(self, layer_idx):
            self.layer_idx = layer_idx
    
    def test_inspect_logic():
        """æµ‹è¯•inspecté€»è¾‘"""
        # æ¨¡æ‹Ÿè°ƒç”¨æ ˆ
        def inner_function():
            frame = inspect.currentframe()
            layer_idx = None
            while frame:
                frame = frame.f_back
                if frame and 'self' in frame.f_locals:
                    self_obj = frame.f_locals['self']
                    if hasattr(self_obj, 'layer_number'):
                        layer_idx = self_obj.layer_number
                        break
                    elif hasattr(self_obj, 'layer_idx'):
                        layer_idx = self_obj.layer_idx
                        break
            return layer_idx
        
        def middle_function():
            return inner_function()
        
        def outer_function_with_layer():
            self = MockTransformerLayer(5)
            return middle_function()
        
        def outer_function_with_mlp():
            self = MockMLP(3)
            return middle_function()
        
        # æµ‹è¯•layer_number
        result1 = outer_function_with_layer()
        print(f"æ£€æµ‹åˆ°layer_number: {result1}")
        assert result1 == 5, f"æœŸæœ›5ï¼Œå®é™…{result1}"
        
        # æµ‹è¯•layer_idx
        result2 = outer_function_with_mlp()
        print(f"æ£€æµ‹åˆ°layer_idx: {result2}")
        assert result2 == 3, f"æœŸæœ›3ï¼Œå®é™…{result2}"
        
        print("âœ… layer_idxæ£€æµ‹é€»è¾‘æµ‹è¯•é€šè¿‡ï¼")
    
    test_inspect_logic()

def test_sample_count_estimation():
    """æµ‹è¯•sampleæ•°é‡ä¼°ç®—"""
    print("\næµ‹è¯•sampleæ•°é‡ä¼°ç®—...")
    
    # æ¨¡æ‹Ÿå‚æ•°
    global_batch_size = 128
    micro_batch_size = 1
    num_microbatches = global_batch_size // micro_batch_size
    num_layers = 32  # å‡è®¾32å±‚
    num_ranks = 8    # å‡è®¾8ä¸ªrank
    
    # ä¼°ç®—tensoræ•°é‡
    # æ¯ä¸ªmicro batchï¼Œæ¯ä¸ªrankï¼Œæ¯ä¸ªlayerå¯èƒ½ç”Ÿæˆå¤šä¸ªtensor
    tensors_per_microbatch_per_rank_per_layer = 4  # attention: query, key, value, weights; linear: input, output
    total_tensors = num_microbatches * num_ranks * num_layers * tensors_per_microbatch_per_rank_per_layer
    
    print(f"å‚æ•°è®¾ç½®:")
    print(f"  global_batch_size: {global_batch_size}")
    print(f"  micro_batch_size: {micro_batch_size}")
    print(f"  num_microbatches: {num_microbatches}")
    print(f"  num_layers: {num_layers}")
    print(f"  num_ranks: {num_ranks}")
    print(f"  tensors_per_microbatch_per_rank_per_layer: {tensors_per_microbatch_per_rank_per_layer}")
    print(f"  ä¼°ç®—æ€»tensoræ•°é‡: {total_tensors}")
    
    # å®é™…æ”¶é›†åˆ°çš„æ•°é‡
    actual_tensors = 56
    print(f"  å®é™…æ”¶é›†åˆ°çš„æ•°é‡: {actual_tensors}")
    
    if actual_tensors < total_tensors * 0.1:  # å¦‚æœå°‘äº10%
        print(f"âŒ æ”¶é›†æ•°é‡è¿‡å°‘ï¼æœŸæœ›è‡³å°‘ {total_tensors * 0.1}ï¼Œå®é™… {actual_tensors}")
    else:
        print(f"âœ… æ”¶é›†æ•°é‡åˆç†")
    
    # åˆ†æå¯èƒ½çš„åŸå› 
    print(f"\nå¯èƒ½çš„åŸå› åˆ†æ:")
    print(f"1. sample_idxæ²¡æœ‰æ­£ç¡®æ›´æ–°ï¼Œå¯¼è‡´åªæ”¶é›†äº†ç¬¬ä¸€ä¸ªsample")
    print(f"2. layer_idxæ²¡æœ‰æ­£ç¡®è®¾ç½®ï¼Œå¯¼è‡´linearå±‚æ²¡æœ‰å±‚æ•°æ ‡è¯†")
    print(f"3. æŸäº›tensorä¿å­˜è¢«è·³è¿‡")

def test_filename_patterns():
    """æµ‹è¯•æ–‡ä»¶åæ¨¡å¼"""
    print("\næµ‹è¯•æ–‡ä»¶åæ¨¡å¼...")
    
    # æ¨¡æ‹Ÿæ–‡ä»¶å
    filenames = [
        "20250914_022153_0003_iter000_linear_forward_post_linear_bf16_rank02_sample000_group000_output.pt",
        "20250914_022153_0004_iter000_attention_L1_forward_pre_FA_bf16_rank00_sample000_group000_query.pt",
    ]
    
    print("æ–‡ä»¶ååˆ†æ:")
    for filename in filenames:
        parts = filename.split('_')
        print(f"  {filename}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰layeræ ‡è¯†
        has_layer = any(part.startswith('L') and part[1:].isdigit() for part in parts)
        print(f"    æœ‰layeræ ‡è¯†: {has_layer}")
        
        # æ£€æŸ¥sample_idx
        sample_parts = [part for part in parts if part.startswith('sample')]
        if sample_parts:
            sample_idx = sample_parts[0].replace('sample', '')
            print(f"    sample_idx: {sample_idx}")
        
        # æ£€æŸ¥iteration
        iter_parts = [part for part in parts if part.startswith('iter')]
        if iter_parts:
            iteration = iter_parts[0].replace('iter', '')
            print(f"    iteration: {iteration}")
        
        print()

if __name__ == "__main__":
    test_layer_idx_detection()
    test_sample_count_estimation()
    test_filename_patterns()
    
    print("\nğŸ¯ é—®é¢˜æ€»ç»“:")
    print("1. Linearå±‚ç¼ºå°‘layer_idxæ ‡è¯†")
    print("2. æ”¶é›†çš„tensoræ•°é‡è¿‡å°‘ï¼ˆ56ä¸ª vs é¢„æœŸæ•°åƒä¸ªï¼‰")
    print("3. å¯èƒ½sample_idxæ²¡æœ‰æ­£ç¡®æ›´æ–°")
    print("\nğŸ”§ ä¿®å¤æ–¹æ¡ˆ:")
    print("1. æ·»åŠ layer_idxæ£€æµ‹é€»è¾‘")
    print("2. ç¡®ä¿sample_idxæ­£ç¡®æ›´æ–°")
    print("3. éªŒè¯tensorä¿å­˜é€»è¾‘")
