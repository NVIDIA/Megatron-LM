type: basic
format_version: 1
maintainers: [mcore]
loggers: [stdout]
spec:
  name: "{test_case}_{environment}_{platforms}"
  model: gpt
  build: mcore-pyt-{environment}
  nodes: 1
  gpus: 1
  n_repeat: 1
  platforms: dgx_a100
  script_setup: |
    unset https_proxy
    echo "machine gitlab-master.nvidia.com login okoenig password $RO_API_TOKEN" | tee -a /root/.netrc

    # Checkout latest
    cd /opt
    rm -rf /opt/megatron-lm; mkdir megatron-lm; cd megatron-lm
    git init
    git remote add origin $MCORE_REPO
    git fetch origin '+refs/merge-requests/*:refs/remotes/merge-requests/*'
    git fetch origin $MCORE_MR_COMMIT
    git checkout $MCORE_MR_COMMIT
    git rev-parse HEAD
    # Checkout backwards-ref
    cd /opt
    rm -rf /opt/megatron-lm-legacy; mkdir megatron-lm-legacy; cd megatron-lm-legacy
    git init
    git remote add origin $MCORE_REPO
    git fetch origin $MCORE_BACKWARDS_COMMIT
    git checkout $MCORE_BACKWARDS_COMMIT
    git rev-parse HEAD
    rm -rf megatron; cp -a /opt/megatron-lm/megatron ./
  script: |-
    ls
    cd /opt/megatron-lm

    ARGUMENTS=(
        "CHECKPOINT_LOAD_PATH=/mnt/artifacts/"
        "CHECKPOINT_SAVE_PATH=/tmp/checkpoints"
        "DATA_PATH=null"
        "DATA_CACHE_PATH=/workspace/data/cache" 
        "TRAINING_SCRIPT_PATH=examples/inference/gpt/gpt_static_inference.py"
        "TRAINING_PARAMS_PATH=./tests/functional_tests/test_cases/{model}/{test_case}/model_config.yaml"
        "GOLDEN_VALUES_PATH=./tests/functional_tests/test_cases/{model}/{test_case}/golden_values_{environment}_{platforms}.json"
        "OUTPUT_PATH={assets_dir}"
        "TENSORBOARD_PATH={assets_dir}/generations_{environment}_{platforms}.json"
        "N_REPEAT={n_repeat}"
        "ENABLE_LIGHTWEIGHT_MODE=${{ENABLE_LIGHTWEIGHT_MODE}}"
        "RECORD_CHECKPOINTS=${{RECORD_CHECKPOINTS}}"
    )

    bash ./tests/functional_tests/shell_test_utils/run_ci_test.sh ${{ARGUMENTS[@]}}

products:
  - test_case: [gpt_static_inference_tp1_pp1_583m_logitsmatch]
    products:
      - environment: [dev]
        scope: [mr, mr-github]
        platforms: [dgx_h100]
  - test_case: [gpt_static_inference_tp1_pp1_583m_cudagraphs]
    products:
      - environment: [dev]
        scope: [mr, mr-github]
        platforms: [dgx_h100]
  - test_case: [gpt_static_inference_tp1_pp1_583m_fp8_cudagraphs]
    products:
      - environment: [dev]
        scope: [mr, mr-github]
        platforms: [dgx_h100]
  - test_case: [gpt_static_inference_tp1_pp1_16b_multiprompt_tokensmatch]
    products:
      - environment: [dev]
        scope: [mr, mr-github]
        platforms: [dgx_h100]
